{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('StudentPerformancePred.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'subsample': 1, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 1}\n",
      "Question 1 accuracy: 0.7273500347853105 f1: 0.8420765776953882\n",
      "Best hyperparameters for question 2: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "Question 2 accuracy: 0.980267610485576 f1: 0.9900354266090516\n",
      "Best hyperparameters for question 3: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 3 accuracy: 0.9359220809045532 f1: 0.9669005007379587\n",
      "Best hyperparameters for question 4: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 1}\n",
      "Question 4 accuracy: 0.7901545188257199 f1: 0.8827222850315637\n",
      "Best hyperparameters for question 5: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 5 accuracy: 0.5289623170393986 f1: 0.6603053272506263\n",
      "Best hyperparameters for question 6: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 6 accuracy: 0.7793341483677921 f1: 0.8758947750071627\n",
      "Best hyperparameters for question 7: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 7 accuracy: 0.7292595119249448 f1: 0.8434355357170306\n",
      "Best hyperparameters for question 8: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 8 accuracy: 0.6072547072742951 f1: 0.7538128830629411\n",
      "Best hyperparameters for question 9: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 9 accuracy: 0.733078691351854 f1: 0.8459840361927228\n",
      "Best hyperparameters for question 10: {'subsample': 1, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.2, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 10 accuracy: 0.5215382987393984 f1: 0.531874648190831\n",
      "Best hyperparameters for question 11: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 11 accuracy: 0.6367497236312711 f1: 0.7776026493909391\n",
      "Best hyperparameters for question 12: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 12 accuracy: 0.8661150549472817 f1: 0.9282546716439211\n",
      "Best hyperparameters for question 13: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 13 accuracy: 0.7197116759314921 f1: 0.004511405237961137\n",
      "Best hyperparameters for question 14: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 14 accuracy: 0.7071932419684208 f1: 0.8284854693053862\n",
      "Best hyperparameters for question 15: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 15 accuracy: 0.5134665306774918 f1: 0.4460885847114177\n",
      "Best hyperparameters for question 16: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 16 accuracy: 0.7313813032896321 f1: 0.8448528946124784\n",
      "Best hyperparameters for question 17: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 17 accuracy: 0.687248313081303 f1: 0.8145903557279013\n",
      "Best hyperparameters for question 18: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 18 accuracy: 0.9537452184269835 f1: 0.97632500393675\n",
      "Overall accuracy: 0.7304851656473733 Overall f1: 0.7674307238923351\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('StudentPerformancePred.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "total_accuracy = 0\n",
    "total_accuracy2 = 0\n",
    "\n",
    "# Define the parameter grid for the search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Create an empty list to store the best parameters for each question\n",
    "best_params_list = []\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    # Create the XGBoost model\n",
    "    model = xgb.XGBClassifier(eval_metric='error', use_label_encoder=False)\n",
    "\n",
    "    # Create the RandomizedSearchCV object\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20, cv=3, scoring='accuracy', n_jobs=-1, verbose=0, random_state=42)\n",
    "\n",
    "    # Fit the RandomizedSearchCV object to the data\n",
    "    random_search.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    best_params_list.append(best_params)\n",
    "    print(f\"Best hyperparameters for question {q_no}:\", best_params)\n",
    "\n",
    "    # Get the best estimator and fit it to the data\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(train_X, train_y)\n",
    "\n",
    "       # Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_accuracy = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5))\n",
    "    question_accuracy2 = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "    total_accuracy += question_accuracy\n",
    "    total_accuracy2 += question_accuracy2\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"f1:\", question_accuracy2)\n",
    "\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_accuracy2 = total_accuracy2 / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall f1:\", overall_accuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 12, 'min_samples_split': 8, 'n_estimators': 237}\n",
      "Question 1 accuracy: 0.7235308553584012 f1: 0.8395913603637742\n",
      "Best hyperparameters for question 2: {'criterion': 'entropy', 'max_depth': 37, 'min_samples_leaf': 11, 'min_samples_split': 12, 'n_estimators': 312}\n",
      "Question 2 accuracy: 0.9779335048958353 f1: 0.9888436167402521\n",
      "Best hyperparameters for question 3: {'criterion': 'gini', 'max_depth': 29, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 135}\n",
      "Question 3 accuracy: 0.9310417806476596 f1: 0.9642896281516811\n",
      "Best hyperparameters for question 4: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 351}\n",
      "Question 4 accuracy: 0.8016127325493694 f1: 0.8900139804255083\n",
      "Best hyperparameters for question 5: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 19, 'min_samples_split': 7, 'n_estimators': 331}\n",
      "Question 5 accuracy: 0.5429683014636848 f1: 0.687276776257302\n",
      "Best hyperparameters for question 6: {'criterion': 'entropy', 'max_depth': 39, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 296}\n",
      "Question 6 accuracy: 0.7699981763041115 f1: 0.8698878181087849\n",
      "Best hyperparameters for question 7: {'criterion': 'entropy', 'max_depth': 37, 'min_samples_leaf': 17, 'min_samples_split': 7, 'n_estimators': 357}\n",
      "Question 7 accuracy: 0.7445364547802221 f1: 0.8535636047178434\n",
      "Best hyperparameters for question 8: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_leaf': 13, 'min_samples_split': 19, 'n_estimators': 298}\n",
      "Question 8 accuracy: 0.6252919602029031 f1: 0.7693896805507003\n",
      "Best hyperparameters for question 9: {'criterion': 'gini', 'max_depth': 34, 'min_samples_leaf': 3, 'min_samples_split': 19, 'n_estimators': 175}\n",
      "Question 9 accuracy: 0.7349886187867695 f1: 0.8471131489004614\n",
      "Best hyperparameters for question 10: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 363}\n",
      "Question 10 accuracy: 0.494371083838227 f1: 0.4896654010932213\n",
      "Best hyperparameters for question 11: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 18, 'min_samples_split': 4, 'n_estimators': 138}\n",
      "Question 11 accuracy: 0.6490558433692895 f1: 0.7871299165689236\n",
      "Best hyperparameters for question 12: {'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 7, 'min_samples_split': 12, 'n_estimators': 147}\n",
      "Question 12 accuracy: 0.8676003539320909 f1: 0.9291070322823932\n",
      "Best hyperparameters for question 13: {'criterion': 'gini', 'max_depth': 17, 'min_samples_leaf': 3, 'min_samples_split': 19, 'n_estimators': 388}\n",
      "Question 13 accuracy: 0.736049064173832 f1: 0.0015999999999999996\n",
      "Best hyperparameters for question 14: {'criterion': 'entropy', 'max_depth': 31, 'min_samples_leaf': 13, 'min_samples_split': 5, 'n_estimators': 144}\n",
      "Question 14 accuracy: 0.7059198069133833 f1: 0.8277576776246555\n",
      "Best hyperparameters for question 15: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 19, 'n_estimators': 433}\n",
      "Question 15 accuracy: 0.5132560176335633 f1: 0.22965432898860919\n",
      "Best hyperparameters for question 16: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 212}\n",
      "Question 16 accuracy: 0.735200707864182 f1: 0.8473955272425473\n",
      "Best hyperparameters for question 17: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 17, 'min_samples_split': 17, 'n_estimators': 241}\n",
      "Question 17 accuracy: 0.6863995064763719 f1: 0.8140413455715592\n",
      "Best hyperparameters for question 18: {'criterion': 'gini', 'max_depth': 21, 'min_samples_leaf': 9, 'min_samples_split': 11, 'n_estimators': 286}\n",
      "Question 18 accuracy: 0.9501379029298462 f1: 0.974431501819141\n",
      "Overall accuracy: 0.7327718151177636 Overall f1: 0.7561529080781865\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('StudentPerformancePred.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "total_accuracy = 0\n",
    "total_accuracy2 = 0\n",
    "\n",
    "# Create an empty list to store the best parameters for each question\n",
    "best_params_list_randomforest = []\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(100, 500),\n",
    "        'max_depth': randint(1, 50),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 20),\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    }\n",
    "\n",
    "    base_model = RandomForestClassifier()\n",
    "\n",
    "    random_search = RandomizedSearchCV(base_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    random_search.fit(train_X, train_y)\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    best_params_list_randomforest.append(best_params)\n",
    "    print(f\"Best hyperparameters for question {q_no}:\", best_params)\n",
    "\n",
    "    # Get the best estimator and fit it to the data\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(train_X, train_y)\n",
    "\n",
    "       # Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_accuracy = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5))\n",
    "    question_accuracy2 = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "    total_accuracy += question_accuracy\n",
    "    total_accuracy2 += question_accuracy2\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"f1:\", question_accuracy2)\n",
    "\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_accuracy2 = total_accuracy2 / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall f1:\", overall_accuracy2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 300, 'depth': 3}\n",
      "Question 1 accuracy: 0.7315933923670446 f1: 0.8449944300999128\n",
      "Best hyperparameters for question 2: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 100, 'depth': 8}\n",
      "Question 2 accuracy: 0.978357908198301 f1: 0.9890605103363157\n",
      "Best hyperparameters for question 3: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 8}\n",
      "Question 3 accuracy: 0.932739393857522 f1: 0.9651992717529035\n",
      "Best hyperparameters for question 4: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 300, 'depth': 6}\n",
      "Question 4 accuracy: 0.8026734030840725 f1: 0.8905366867595094\n",
      "Best hyperparameters for question 5: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 4}\n",
      "Question 5 accuracy: 0.5503941209448097 f1: 0.7075917013795741\n",
      "Best hyperparameters for question 6: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 100, 'depth': 4}\n",
      "Question 6 accuracy: 0.7727562349010363 f1: 0.871813248765541\n",
      "Best hyperparameters for question 7: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 6}\n",
      "Question 7 accuracy: 0.7394442905935567 f1: 0.8502074435631481\n",
      "Best hyperparameters for question 8: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 700, 'depth': 3}\n",
      "Question 8 accuracy: 0.6242308393729188 f1: 0.7686478636047195\n",
      "Best hyperparameters for question 9: {'verbose': 0, 'learning_rate': 0.1, 'iterations': 100, 'depth': 4}\n",
      "Question 9 accuracy: 0.7339272728091446 f1: 0.846511121438812\n",
      "Best hyperparameters for question 10: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 100, 'depth': 4}\n",
      "Question 10 accuracy: 0.4854613162581362 f1: 0.4763551075098283\n",
      "Best hyperparameters for question 11: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 300, 'depth': 3}\n",
      "Question 11 accuracy: 0.6303847998324901 f1: 0.7725247709830152\n",
      "Best hyperparameters for question 12: {'verbose': 0, 'learning_rate': 0.1, 'iterations': 100, 'depth': 3}\n",
      "Question 12 accuracy: 0.8676003539320909 f1: 0.9291070322823932\n",
      "Best hyperparameters for question 13: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 700, 'depth': 6}\n",
      "Question 13 accuracy: 0.7186505551015079 f1: 0.0\n",
      "Best hyperparameters for question 14: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 100, 'depth': 4}\n",
      "Question 14 accuracy: 0.7067686135183147 f1: 0.8281949216891658\n",
      "Best hyperparameters for question 15: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 6}\n",
      "Question 15 accuracy: 0.4988330597789501 f1: 0.3950397696801813\n",
      "Best hyperparameters for question 16: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 4}\n",
      "Question 16 accuracy: 0.7358369750964195 f1: 0.8478180605605466\n",
      "Best hyperparameters for question 17: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 700, 'depth': 4}\n",
      "Question 17 accuracy: 0.690006371678228 f1: 0.8165724469216922\n",
      "Best hyperparameters for question 18: {'verbose': 0, 'learning_rate': 0.2, 'iterations': 100, 'depth': 3}\n",
      "Question 18 accuracy: 0.9450457387431808 f1: 0.971746500349014\n",
      "Overall accuracy: 0.7302613688926513 Overall f1: 0.7651067159820151\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already read and preprocessed the data\n",
    "train = pd.read_csv('CatBoostData.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "# Specify the categorical columns to be used by the CatBoost model\n",
    "cat_features = ['event_name_mode', 'fqid_mode', 'room_fqid_mode', 'text_mode']\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "total_accuracy = 0\n",
    "total_accuracy2 = 0\n",
    "\n",
    "# Create an empty list to store the best parameters for each question\n",
    "best_params_list_catboost = []\n",
    "\n",
    "# Hyperparameter tuning configuration\n",
    "param_dist = {\n",
    "    'iterations': [100, 300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'depth': [3, 4, 6, 8],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "# Loop through questions, create train & validation sets for each question\n",
    "for q_no in range(1, 19):\n",
    "\n",
    "    # Filter dataset based on current question\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "\n",
    "    # Create train & validation sets\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    # Hyperparameter tuning for the CatBoost model\n",
    "    catboost_base_model = CatBoostClassifier(cat_features=cat_features)\n",
    "    catboost_random_search = RandomizedSearchCV(catboost_base_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    catboost_random_search.fit(train_X, train_y)\n",
    "   \n",
    "    best_params = catboost_random_search.best_params_\n",
    "    best_params_list_catboost.append(best_params)\n",
    "    print(f\"Best hyperparameters for question {q_no}:\", best_params)\n",
    "\n",
    "    # Get the best estimator and fit it to the data\n",
    "    best_model = catboost_random_search.best_estimator_\n",
    "    best_model.fit(train_X, train_y)\n",
    "\n",
    "       # Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_accuracy = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5))\n",
    "    question_accuracy2 = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "    total_accuracy += question_accuracy\n",
    "    total_accuracy2 += question_accuracy2\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"f1:\", question_accuracy2)\n",
    "\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_accuracy2 = total_accuracy2 / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall f1:\", overall_accuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 1}\n",
      "Question 1 accuracy: 0.7194989114111578 f1: 0.8367895416417561\n",
      "Best hyperparameters for question 2: {'subsample': 0.8, 'n_estimators': 500, 'min_child_samples': 30, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 2 accuracy: 0.978782086353126 f1: 0.9892772863392352\n",
      "Best hyperparameters for question 3: {'subsample': 0.8, 'n_estimators': 500, 'min_child_samples': 30, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "Question 3 accuracy: 0.9246764065535975 f1: 0.9608640287507871\n",
      "Best hyperparameters for question 4: {'subsample': 1, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 1}\n",
      "Question 4 accuracy: 0.7971568355949413 f1: 0.8871310193345986\n",
      "Best hyperparameters for question 5: {'subsample': 1, 'n_estimators': 200, 'min_child_samples': 20, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 5 accuracy: 0.5319340407472201 f1: 0.6738970619259234\n",
      "Best hyperparameters for question 6: {'subsample': 1, 'n_estimators': 200, 'min_child_samples': 10, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 6 accuracy: 0.7842139983294045 f1: 0.8790581563663631\n",
      "Best hyperparameters for question 7: {'subsample': 1, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 7 accuracy: 0.7328666022744414 f1: 0.8458430197837046\n",
      "Best hyperparameters for question 8: {'subsample': 1, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 8 accuracy: 0.5962231483295171 f1: 0.7444531445503054\n",
      "Best hyperparameters for question 9: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 10, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 9 accuracy: 0.7462338428424439 f1: 0.8546779644159515\n",
      "Best hyperparameters for question 10: {'subsample': 1, 'n_estimators': 100, 'min_child_samples': 30, 'max_depth': 6, 'learning_rate': 0.2, 'colsample_bytree': 1}\n",
      "Question 10 accuracy: 0.4990476254804088 f1: 0.5003983254501257\n",
      "Best hyperparameters for question 11: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 11 accuracy: 0.6450245748649677 f1: 0.784212641168029\n",
      "Best hyperparameters for question 12: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 30, 'max_depth': 6, 'learning_rate': 0.05, 'colsample_bytree': 1}\n",
      "Question 12 accuracy: 0.8735415498713281 f1: 0.9325026856433203\n",
      "Best hyperparameters for question 13: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 30, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 13 accuracy: 0.7214090639937137 f1: 0.0\n",
      "Best hyperparameters for question 14: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 14 accuracy: 0.7025248056412993 f1: 0.8252739608939142\n",
      "Best hyperparameters for question 15: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 30, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 15 accuracy: 0.4975535457376175 f1: 0.40067270089871415\n",
      "Best hyperparameters for question 16: {'subsample': 1, 'n_estimators': 500, 'min_child_samples': 20, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 16 accuracy: 0.7324421989719759 f1: 0.8455600987648904\n",
      "Best hyperparameters for question 17: {'subsample': 0.8, 'n_estimators': 500, 'min_child_samples': 20, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 17 accuracy: 0.695099211307815 f1: 0.8199027833807129\n",
      "Best hyperparameters for question 18: {'subsample': 1, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "Question 18 accuracy: 0.9505625313799524 f1: 0.9746546977262682\n",
      "Overall accuracy: 0.7293772766491626 Overall f1: 0.7641760620574777\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already read and preprocessed the data\n",
    "train = pd.read_csv('StudentPerformancePred.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "total_accuracy = 0\n",
    "total_accuracy2 = 0\n",
    "\n",
    "# Define the parameter grid for the search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Create an empty list to store the best parameters for each question\n",
    "best_params_list_lightGBM = []\n",
    "\n",
    "# Loop through questions, create train & validation sets for each question\n",
    "for q_no in range(1, 19):\n",
    "\n",
    "    # Filter dataset based on current question\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "\n",
    "    # Create train & validation sets\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    # Create the LightGBM model\n",
    "    model = LGBMClassifier()\n",
    "\n",
    "    # Create the RandomizedSearchCV object\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20, cv=3, scoring='accuracy', n_jobs=-1, verbose=0)\n",
    "\n",
    "    # Fit the RandomizedSearchCV object to the data\n",
    "    random_search.fit(train_X, train_y)\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    best_params_list_lightGBM.append(best_params)\n",
    "    print(f\"Best hyperparameters for question {q_no}:\", best_params)\n",
    "\n",
    "    # Get the best estimator and fit it to the data\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(train_X, train_y)\n",
    "\n",
    "       # Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_accuracy = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5))\n",
    "    question_accuracy2 = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "    total_accuracy += question_accuracy\n",
    "    total_accuracy2 += question_accuracy2\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"f1:\", question_accuracy2)\n",
    "\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_accuracy2 = total_accuracy2 / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall f1:\", overall_accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 accuracy: 0.7254402715892213 F1 score: 0.8408755533694049\n",
      "Question 2 accuracy: 0.9813282410354339 F1 score: 0.990576140501178\n",
      "Question 3 accuracy: 0.9329514109908763 F1 score: 0.9653128430296377\n",
      "Question 4 accuracy: 0.7937619350732018 F1 score: 0.8850248403122781\n",
      "Question 5 accuracy: 0.5461489497135582 F1 score: 0.7064635652531907\n",
      "Question 6 accuracy: 0.7721196690006366 F1 score: 0.8714080459770115\n",
      "Question 7 accuracy: 0.7307447485677913 F1 score: 0.8444280985656492\n",
      "Question 8 accuracy: 0.61001485253554 F1 score: 0.7577754348972061\n",
      "Question 9 accuracy: 0.7362614046255039 F1 score: 0.8480997189294879\n",
      "Question 10 accuracy: 0.5077445363887121 F1 score: 0.5387673956262427\n",
      "Question 11 accuracy: 0.6397199236155315 F1 score: 0.7802795031055901\n",
      "Question 12 accuracy: 0.862295777636325 F1 score: 0.9260567392047396\n",
      "Question 13 accuracy: 0.7383831954169319 F1 score: 0.0\n",
      "Question 14 accuracy: 0.7158922130277955 F1 score: 0.834425621367627\n",
      "Question 15 accuracy: 0.5138977296838532 F1 score: 0.011221406991799743\n",
      "Question 16 accuracy: 0.7209845109272226 F1 score: 0.8378744914313895\n",
      "Question 17 accuracy: 0.6870358582643752 F1 score: 0.8144887435542699\n",
      "Question 18 accuracy: 0.9511988117971568 F1 score: 0.974989125706829\n",
      "Overall accuracy: 0.7314402244383147 Overall F1 score: 0.7460037371013071\n"
     ]
    }
   ],
   "source": [
    "train_other = pd.read_csv(\"StudentPerformancePred.csv\")\n",
    "train_catboost = pd.read_csv(\"CatBoostData.csv\")\n",
    "labels = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "labels[\"session\"] = labels.session_id.apply(lambda x: int(x.split(\"_\")[0]))\n",
    "labels[\"q\"] = labels.session_id.apply(lambda x: int(x.split(\"_\")[-1][1:]))\n",
    "\n",
    "train_other[\"session_id\"] = train_other[\"session_id\"].astype(str)\n",
    "train_catboost[\"session_id\"] = train_catboost[\"session_id\"].astype(str)\n",
    "labels[\"session\"] = labels[\"session\"].astype(str)\n",
    "\n",
    "cat_features = [\"event_name_mode\", \"fqid_mode\", \"room_fqid_mode\", \"text_mode\"]\n",
    "\n",
    "total_accuracy = 0\n",
    "total_f1_score = 0\n",
    "\n",
    "# Initialize the second-level model (meta-learner)\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select_other = train_other[train_other[\"level_group\"] == \"0-4\"]\n",
    "        select_catboost = train_catboost[train_catboost[\"level_group\"] == \"0-4\"]\n",
    "    elif q_no <= 13:\n",
    "        select_other = train_other[train_other[\"level_group\"] == \"5-12\"]\n",
    "        select_catboost = train_catboost[train_catboost[\"level_group\"] == \"5-12\"]\n",
    "    else:\n",
    "        select_other = train_other[train_other[\"level_group\"] == \"13-22\"]\n",
    "        select_catboost = train_catboost[train_catboost[\"level_group\"] == \"13-22\"]\n",
    "\n",
    "    train_X_other, validate_X_other = train_test_split(select_other, test_size=0.2)\n",
    "    train_X_catboost, validate_X_catboost = train_test_split(\n",
    "        select_catboost, test_size=0.2\n",
    "    )\n",
    "\n",
    "    train_y = labels.loc[\n",
    "        (labels[\"session\"].isin(train_X_other[\"session_id\"])) & (labels[\"q\"] == q_no)\n",
    "    ]\n",
    "    validate_y = labels.loc[\n",
    "        (labels[\"session\"].isin(validate_X_other[\"session_id\"])) & (labels[\"q\"] == q_no)\n",
    "    ]\n",
    "\n",
    "    train_X_other = train_X_other.drop([\"session_id\", \"level_group\"], axis=1)\n",
    "    train_X_catboost = train_X_catboost.drop([\"session_id\", \"level_group\"], axis=1)\n",
    "    train_y = train_y[\"correct\"]\n",
    "\n",
    "    validate_X_other = validate_X_other.drop([\"session_id\", \"level_group\"], axis=1)\n",
    "    validate_X_catboost = validate_X_catboost.drop(\n",
    "        [\"session_id\", \"level_group\"], axis=1\n",
    "    )\n",
    "    validate_y = validate_y[\"correct\"]\n",
    "\n",
    "    # Train the four models with the optimized hyperparameters\n",
    "    rf_model = RandomForestClassifier(**best_params_list_randomforest[q_no - 1])\n",
    "    xgb_model = XGBClassifier(**best_params_list[q_no - 1])\n",
    "    cat_model = CatBoostClassifier(cat_features=cat_features, **best_params_list_catboost[q_no - 1])\n",
    "    lgbm_model = LGBMClassifier(**best_params_list_lightGBM[q_no - 1])\n",
    "\n",
    "    rf_model.fit(train_X_other, train_y)\n",
    "    xgb_model.fit(train_X_other, train_y)\n",
    "    cat_model.fit(train_X_catboost, train_y)\n",
    "    lgbm_model.fit(train_X_other, train_y)\n",
    "\n",
    "    # Obtain the predictions\n",
    "    rf_pred = rf_model.predict_proba(validate_X_other)[:, 1]\n",
    "    xgb_pred = xgb_model.predict_proba(validate_X_other)[:, 1]\n",
    "    cat_pred = cat_model.predict_proba(validate_X_catboost)[:, 1]\n",
    "    lgbm_pred = lgbm_model.predict_proba(validate_X_other)[:, 1]\n",
    "\n",
    "    # Stack the predictions\n",
    "    stacked_predictions = np.column_stack((rf_pred, xgb_pred, cat_pred, lgbm_pred))\n",
    "\n",
    "    # Train the meta-learner\n",
    "    meta_learner.fit(stacked_predictions, validate_y)\n",
    "\n",
    "    # Use the meta-learner to make the final prediction\n",
    "    ensemble_pred = meta_learner.predict(stacked_predictions)\n",
    "\n",
    "    # Calculate the accuracy and F1 score of the ensemble model\n",
    "    question_accuracy = np.mean(ensemble_pred == validate_y)\n",
    "    question_f1_score = f1_score(validate_y, ensemble_pred)\n",
    "\n",
    "    total_accuracy += question_accuracy\n",
    "    total_f1_score += question_f1_score\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"F1 score:\", question_f1_score)\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_f1_score = total_f1_score / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall F1 score:\", overall_f1_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
