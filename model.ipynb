{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('StudentPerformancePred.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'subsample': 1, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 1}\n",
      "Question 1 accuracy: 0.7273500347853105 f1: 0.8420765776953882\n",
      "Best hyperparameters for question 2: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "Question 2 accuracy: 0.980267610485576 f1: 0.9900354266090516\n",
      "Best hyperparameters for question 3: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 3 accuracy: 0.9359220809045532 f1: 0.9669005007379587\n",
      "Best hyperparameters for question 4: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 1}\n",
      "Question 4 accuracy: 0.7901545188257199 f1: 0.8827222850315637\n",
      "Best hyperparameters for question 5: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 5 accuracy: 0.5289623170393986 f1: 0.6603053272506263\n",
      "Best hyperparameters for question 6: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 6 accuracy: 0.7793341483677921 f1: 0.8758947750071627\n",
      "Best hyperparameters for question 7: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 7 accuracy: 0.7292595119249448 f1: 0.8434355357170306\n",
      "Best hyperparameters for question 8: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 8 accuracy: 0.6072547072742951 f1: 0.7538128830629411\n",
      "Best hyperparameters for question 9: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 9 accuracy: 0.733078691351854 f1: 0.8459840361927228\n",
      "Best hyperparameters for question 10: {'subsample': 1, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.2, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 10 accuracy: 0.5215382987393984 f1: 0.531874648190831\n",
      "Best hyperparameters for question 11: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 11 accuracy: 0.6367497236312711 f1: 0.7776026493909391\n",
      "Best hyperparameters for question 12: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 12 accuracy: 0.8661150549472817 f1: 0.9282546716439211\n",
      "Best hyperparameters for question 13: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 13 accuracy: 0.7197116759314921 f1: 0.004511405237961137\n",
      "Best hyperparameters for question 14: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 14 accuracy: 0.7071932419684208 f1: 0.8284854693053862\n",
      "Best hyperparameters for question 15: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 15 accuracy: 0.5134665306774918 f1: 0.4460885847114177\n",
      "Best hyperparameters for question 16: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 16 accuracy: 0.7313813032896321 f1: 0.8448528946124784\n",
      "Best hyperparameters for question 17: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 17 accuracy: 0.687248313081303 f1: 0.8145903557279013\n",
      "Best hyperparameters for question 18: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 18 accuracy: 0.9537452184269835 f1: 0.97632500393675\n",
      "Overall accuracy: 0.7304851656473733 Overall f1: 0.7674307238923351\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "train = pd.read_csv('StudentPerformancePred.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "total_accuracy = 0\n",
    "total_accuracy2 = 0\n",
    "\n",
    "# Define the parameter grid for the search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Create an empty list to store the best parameters for each question\n",
    "best_params_list = []\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    # Create the XGBoost model\n",
    "    model = xgb.XGBClassifier(eval_metric='error', use_label_encoder=False)\n",
    "\n",
    "    # Create the RandomizedSearchCV object\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20, cv=3, scoring='accuracy', n_jobs=-1, verbose=0, random_state=42)\n",
    "\n",
    "    # Fit the RandomizedSearchCV object to the data\n",
    "    random_search.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    best_params_list.append(best_params)\n",
    "    print(f\"Best hyperparameters for question {q_no}:\", best_params)\n",
    "\n",
    "    # Get the best estimator and fit it to the data\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(train_X, train_y)\n",
    "\n",
    "       # Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_accuracy = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5))\n",
    "    question_accuracy2 = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "    total_accuracy += question_accuracy\n",
    "    total_accuracy2 += question_accuracy2\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"f1:\", question_accuracy2)\n",
    "\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_accuracy2 = total_accuracy2 / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall f1:\", overall_accuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 12, 'min_samples_split': 8, 'n_estimators': 237}\n",
      "Question 1 accuracy: 0.7235308553584012 f1: 0.8395913603637742\n",
      "Best hyperparameters for question 2: {'criterion': 'entropy', 'max_depth': 37, 'min_samples_leaf': 11, 'min_samples_split': 12, 'n_estimators': 312}\n",
      "Question 2 accuracy: 0.9779335048958353 f1: 0.9888436167402521\n",
      "Best hyperparameters for question 3: {'criterion': 'gini', 'max_depth': 29, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 135}\n",
      "Question 3 accuracy: 0.9310417806476596 f1: 0.9642896281516811\n",
      "Best hyperparameters for question 4: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 351}\n",
      "Question 4 accuracy: 0.8016127325493694 f1: 0.8900139804255083\n",
      "Best hyperparameters for question 5: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 19, 'min_samples_split': 7, 'n_estimators': 331}\n",
      "Question 5 accuracy: 0.5429683014636848 f1: 0.687276776257302\n",
      "Best hyperparameters for question 6: {'criterion': 'entropy', 'max_depth': 39, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 296}\n",
      "Question 6 accuracy: 0.7699981763041115 f1: 0.8698878181087849\n",
      "Best hyperparameters for question 7: {'criterion': 'entropy', 'max_depth': 37, 'min_samples_leaf': 17, 'min_samples_split': 7, 'n_estimators': 357}\n",
      "Question 7 accuracy: 0.7445364547802221 f1: 0.8535636047178434\n",
      "Best hyperparameters for question 8: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_leaf': 13, 'min_samples_split': 19, 'n_estimators': 298}\n",
      "Question 8 accuracy: 0.6252919602029031 f1: 0.7693896805507003\n",
      "Best hyperparameters for question 9: {'criterion': 'gini', 'max_depth': 34, 'min_samples_leaf': 3, 'min_samples_split': 19, 'n_estimators': 175}\n",
      "Question 9 accuracy: 0.7349886187867695 f1: 0.8471131489004614\n",
      "Best hyperparameters for question 10: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 363}\n",
      "Question 10 accuracy: 0.494371083838227 f1: 0.4896654010932213\n",
      "Best hyperparameters for question 11: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 18, 'min_samples_split': 4, 'n_estimators': 138}\n",
      "Question 11 accuracy: 0.6490558433692895 f1: 0.7871299165689236\n",
      "Best hyperparameters for question 12: {'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 7, 'min_samples_split': 12, 'n_estimators': 147}\n",
      "Question 12 accuracy: 0.8676003539320909 f1: 0.9291070322823932\n",
      "Best hyperparameters for question 13: {'criterion': 'gini', 'max_depth': 17, 'min_samples_leaf': 3, 'min_samples_split': 19, 'n_estimators': 388}\n",
      "Question 13 accuracy: 0.736049064173832 f1: 0.0015999999999999996\n",
      "Best hyperparameters for question 14: {'criterion': 'entropy', 'max_depth': 31, 'min_samples_leaf': 13, 'min_samples_split': 5, 'n_estimators': 144}\n",
      "Question 14 accuracy: 0.7059198069133833 f1: 0.8277576776246555\n",
      "Best hyperparameters for question 15: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 19, 'n_estimators': 433}\n",
      "Question 15 accuracy: 0.5132560176335633 f1: 0.22965432898860919\n",
      "Best hyperparameters for question 16: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 212}\n",
      "Question 16 accuracy: 0.735200707864182 f1: 0.8473955272425473\n",
      "Best hyperparameters for question 17: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 17, 'min_samples_split': 17, 'n_estimators': 241}\n",
      "Question 17 accuracy: 0.6863995064763719 f1: 0.8140413455715592\n",
      "Best hyperparameters for question 18: {'criterion': 'gini', 'max_depth': 21, 'min_samples_leaf': 9, 'min_samples_split': 11, 'n_estimators': 286}\n",
      "Question 18 accuracy: 0.9501379029298462 f1: 0.974431501819141\n",
      "Overall accuracy: 0.7327718151177636 Overall f1: 0.7561529080781865\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "train = pd.read_csv('StudentPerformancePred.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "total_accuracy = 0\n",
    "total_accuracy2 = 0\n",
    "\n",
    "# Create an empty list to store the best parameters for each question\n",
    "best_params_list_randomforest = []\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(100, 500),\n",
    "        'max_depth': randint(1, 50),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 20),\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    }\n",
    "\n",
    "    base_model = RandomForestClassifier()\n",
    "\n",
    "    random_search = RandomizedSearchCV(base_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    random_search.fit(train_X, train_y)\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    best_params_list_randomforest.append(best_params)\n",
    "    print(f\"Best hyperparameters for question {q_no}:\", best_params)\n",
    "\n",
    "    # Get the best estimator and fit it to the data\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(train_X, train_y)\n",
    "\n",
    "       # Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_accuracy = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5))\n",
    "    question_accuracy2 = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "    total_accuracy += question_accuracy\n",
    "    total_accuracy2 += question_accuracy2\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"f1:\", question_accuracy2)\n",
    "\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_accuracy2 = total_accuracy2 / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall f1:\", overall_accuracy2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 700, 'depth': 6}\n",
      "Question 1 accuracy: 0.7207723464661951 f1: 0.8377311467489829\n",
      "Best hyperparameters for question 2: {'verbose': 0, 'learning_rate': 0.1, 'iterations': 700, 'depth': 8}\n",
      "Question 2 accuracy: 0.9779335048958353 f1: 0.9888436167402521\n",
      "Best hyperparameters for question 3: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 8}\n",
      "Question 3 accuracy: 0.9363462590593782 f1: 0.9671268807286563\n",
      "Best hyperparameters for question 4: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 100, 'depth': 8}\n",
      "Question 4 accuracy: 0.8003395226419725 f1: 0.8890983781816713\n",
      "Best hyperparameters for question 5: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 100, 'depth': 3}\n",
      "Question 5 accuracy: 0.5499681416088601 f1: 0.7096508152555747\n",
      "Best hyperparameters for question 6: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 300, 'depth': 4}\n",
      "Question 6 accuracy: 0.7778483990877018 f1: 0.8749849142666578\n",
      "Best hyperparameters for question 7: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 300, 'depth': 6}\n",
      "Question 7 accuracy: 0.7262889139553261 f1: 0.8412497075776658\n",
      "Best hyperparameters for question 8: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 300, 'depth': 6}\n",
      "Question 8 accuracy: 0.6098027031225726 f1: 0.757611671544357\n",
      "Best hyperparameters for question 9: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 300, 'depth': 8}\n",
      "Question 9 accuracy: 0.7360492893214726 f1: 0.8479589277461189\n",
      "Best hyperparameters for question 10: {'verbose': 0, 'learning_rate': 0.1, 'iterations': 500, 'depth': 3}\n",
      "Question 10 accuracy: 0.500527295774204 f1: 0.5010963414134085\n",
      "Best hyperparameters for question 11: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 8}\n",
      "Question 11 accuracy: 0.6305964386146216 f1: 0.7733956120100235\n",
      "Best hyperparameters for question 12: {'verbose': 0, 'learning_rate': 0.1, 'iterations': 100, 'depth': 3}\n",
      "Question 12 accuracy: 0.8631444569776632 f1: 0.9265459286176417\n",
      "Best hyperparameters for question 13: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 300, 'depth': 4}\n",
      "Question 13 accuracy: 0.7309571251348072 f1: 0.0\n",
      "Best hyperparameters for question 14: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 300, 'depth': 8}\n",
      "Question 14 accuracy: 0.706344210215849 f1: 0.8279034948979656\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Assuming you have already read and preprocessed the data\n",
    "train = pd.read_csv('CatBoostData.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "# Specify the categorical columns to be used by the CatBoost model\n",
    "cat_features = ['event_name_mode', 'fqid_mode', 'room_fqid_mode', 'text_mode']\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "total_accuracy = 0\n",
    "total_accuracy2 = 0\n",
    "\n",
    "# Create an empty list to store the best parameters for each question\n",
    "best_params_list_catboost = []\n",
    "\n",
    "# Hyperparameter tuning configuration\n",
    "param_dist = {\n",
    "    'iterations': [100, 300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'depth': [3, 4, 6, 8],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "# Loop through questions, create train & validation sets for each question\n",
    "for q_no in range(1, 19):\n",
    "\n",
    "    # Filter dataset based on current question\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "\n",
    "    # Create train & validation sets\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    # Hyperparameter tuning for the CatBoost model\n",
    "    catboost_base_model = CatBoostClassifier(cat_features=cat_features)\n",
    "    catboost_random_search = RandomizedSearchCV(catboost_base_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    catboost_random_search.fit(train_X, train_y)\n",
    "   \n",
    "    best_params = catboost_random_search.best_params_\n",
    "    best_params_list_catboost.append(best_params)\n",
    "    print(f\"Best hyperparameters for question {q_no}:\", best_params)\n",
    "\n",
    "    # Get the best estimator and fit it to the data\n",
    "    best_model = catboost_random_search.best_estimator_\n",
    "    best_model.fit(train_X, train_y)\n",
    "\n",
    "       # Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_accuracy = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5))\n",
    "    question_accuracy2 = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "    total_accuracy += question_accuracy\n",
    "    total_accuracy2 += question_accuracy2\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"f1:\", question_accuracy2)\n",
    "\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_accuracy2 = total_accuracy2 / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall f1:\", overall_accuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 accuracy: 0.726500327589817 f1: 0.8411191225949011\n",
      "Question 2 accuracy: 0.9781458191208884 f1: 0.988952122334856\n",
      "Question 3 accuracy: 0.9333758862374001 f1: 0.9655399647513658\n",
      "Question 4 accuracy: 0.8047947441534786 f1: 0.8916885854461937\n",
      "Question 5 accuracy: 0.5032916585050647 f1: 0.606575882320669\n",
      "Question 6 accuracy: 0.7693610084813117 f1: 0.8694287893751348\n",
      "Question 7 accuracy: 0.7279867523128292 f1: 0.8423101254175558\n",
      "Question 8 accuracy: 0.5979189603582549 f1: 0.7373968299111142\n",
      "Question 9 accuracy: 0.7405042856853381 f1: 0.8504285894327992\n",
      "Question 10 accuracy: 0.5151675211019626 f1: 0.5085124963333041\n",
      "Question 11 accuracy: 0.6373864411587898 f1: 0.7724626938769334\n",
      "Question 12 accuracy: 0.8688728883965661 f1: 0.9298193276627499\n",
      "Question 13 accuracy: 0.7224690590854953 f1: 0.02374637010006861\n",
      "Question 14 accuracy: 0.7029487586484839 f1: 0.8246906710637946\n",
      "Question 15 accuracy: 0.5094377387972162 f1: 0.4357590685183494\n",
      "Question 16 accuracy: 0.739657505409172 f1: 0.8501270235299823\n",
      "Question 17 accuracy: 0.6910686182464151 f1: 0.81583380555729\n",
      "Question 18 accuracy: 0.9526843227446399 f1: 0.9757688401860992\n",
      "Overall accuracy: 0.7289762386685069 Overall f1: 0.7627866838007313\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Assuming you have already read and preprocessed the data\n",
    "train = pd.read_csv('StudentPerformancePred.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "total_accuracy = 0\n",
    "total_accuracy2 = 0\n",
    "\n",
    "# Define the parameter grid for the search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Create an empty list to store the best parameters for each question\n",
    "best_params_list_lightGBM = []\n",
    "\n",
    "# Loop through questions, create train & validation sets for each question\n",
    "for q_no in range(1, 19):\n",
    "\n",
    "    # Filter dataset based on current question\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "\n",
    "    # Create train & validation sets\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    # Create the LightGBM model\n",
    "    model = LGBMClassifier()\n",
    "\n",
    "    # Create the RandomizedSearchCV object\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20, cv=3, scoring='accuracy', n_jobs=-1, verbose=0)\n",
    "\n",
    "    # Fit the RandomizedSearchCV object to the data\n",
    "    random_search.fit(train_X, train_y)\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    best_params_list_lightGBM.append(best_params)\n",
    "    print(f\"Best hyperparameters for question {q_no}:\", best_params)\n",
    "\n",
    "    # Get the best estimator and fit it to the data\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(train_X, train_y)\n",
    "\n",
    "       # Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_accuracy = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5))\n",
    "    question_accuracy2 = np.mean(cross_val_score(best_model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "    total_accuracy += question_accuracy\n",
    "    total_accuracy2 += question_accuracy2\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy, \"f1:\", question_accuracy2)\n",
    "\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "overall_accuracy2 = total_accuracy2 / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy, \"Overall f1:\", overall_accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 accuracy: 0.7165287502652239\n",
      "Question 2 accuracy: 0.9777211966900063\n",
      "Question 3 accuracy: 0.9295565457245916\n",
      "Question 4 accuracy: 0.80500742626777\n",
      "Question 5 accuracy: 0.539147040101846\n",
      "Question 6 accuracy: 0.7644812221514958\n",
      "Question 7 accuracy: 0.7358370464672184\n",
      "Question 8 accuracy: 0.6040738383195416\n",
      "Question 9 accuracy: 0.7265011669849353\n",
      "Question 10 accuracy: 0.5128368342881392\n",
      "Question 11 accuracy: 0.6346276257161044\n",
      "Question 12 accuracy: 0.8663271801400382\n",
      "Question 13 accuracy: 0.7224697644812221\n",
      "Question 14 accuracy: 0.7008274984086569\n",
      "Question 15 accuracy: 0.4988330150647146\n",
      "Question 16 accuracy: 0.7388075535752174\n",
      "Question 17 accuracy: 0.6893698281349459\n",
      "Question 18 accuracy: 0.954169318905156\n",
      "Overall accuracy: 0.7287290473159348\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "train_other = pd.read_csv('StudentPerformancePred.csv')\n",
    "train_catboost = pd.read_csv('CatBoostData.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]))\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]))\n",
    "\n",
    "train_other['session_id'] = train_other['session_id'].astype(str)\n",
    "train_catboost['session_id'] = train_catboost['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)\n",
    "\n",
    "cat_features = ['event_name_mode', 'fqid_mode', 'room_fqid_mode', 'text_mode']\n",
    "\n",
    "total_accuracy = 0\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select_other = train_other[train_other['level_group'] == '0-4']\n",
    "        select_catboost = train_catboost[train_catboost['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select_other = train_other[train_other['level_group'] == '5-12']\n",
    "        select_catboost = train_catboost[train_catboost['level_group'] == '5-12']\n",
    "    else:\n",
    "        select_other = train_other[train_other['level_group'] == '13-22']\n",
    "        select_catboost = train_catboost[train_catboost['level_group'] == '13-22']\n",
    "\n",
    "    train_X_other, validate_X_other = train_test_split(select_other, test_size=0.2)\n",
    "    train_X_catboost, validate_X_catboost = train_test_split(select_catboost, test_size=0.2)\n",
    "\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X_other['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X_other['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X_other = train_X_other.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_X_catboost = train_X_catboost.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X_other = validate_X_other.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_X_catboost = validate_X_catboost.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    # Train the four models\n",
    "    rf_model = RandomForestClassifier(n_estimators=100)\n",
    "    xgb_model = XGBClassifier()\n",
    "    cat_model = CatBoostClassifier(cat_features=cat_features, iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "    lgbm_model = LGBMClassifier()\n",
    "\n",
    "    # Create the voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[('rf', rf_model), ('xgb', xgb_model), ('cat', cat_model), ('lgbm', lgbm_model)],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    rf_model.fit(train_X_other, train_y)\n",
    "    xgb_model.fit(train_X_other, train_y)\n",
    "    cat_model.fit(train_X_catboost, train_y)\n",
    "    lgbm_model.fit(train_X_other, train_y)\n",
    "\n",
    "    # Obtain the predictions\n",
    "    rf_pred = rf_model.predict_proba(validate_X_other)[:, 1]\n",
    "    xgb_pred = xgb_model.predict_proba(validate_X_other)[:, 1]\n",
    "    cat_pred = cat_model.predict_proba(validate_X_catboost)[:, 1]\n",
    "    lgbm_pred = lgbm_model.predict_proba(validate_X_other)[:, 1]\n",
    "\n",
    "    # Average the predictions\n",
    "    ensemble_pred = (rf_pred + xgb_pred + cat_pred + lgbm_pred) / 4\n",
    "    ensemble_pred = np.round(ensemble_pred).astype(int)\n",
    "\n",
    "    # Calculate the accuracy of the ensemble model\n",
    "    question_accuracy = np.mean(ensemble_pred == validate_y)\n",
    "    total_accuracy += question_accuracy\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_accuracy)\n",
    "\n",
    "overall_accuracy = total_accuracy / 18\n",
    "print(\"Overall accuracy:\", overall_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
