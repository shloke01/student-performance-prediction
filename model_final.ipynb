{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import pickle\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training data\n",
    "train = pd.read_csv('train_preprocessed.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize dictionaries to store models and best parameters for each question for each model type\n",
    "stored_models = {}\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to train models and evaluate on validation data\n",
    "def train_model(train, labels, model_name, model_type, hyperparams, random_search):\n",
    "    ## Initialize vars to store model scores\n",
    "    overall_acc, overall_f1 = 0, 0\n",
    "\n",
    "    ## Initialize array to store best parameters for each question model\n",
    "    best_params_list = []\n",
    "\n",
    "    ## Print model name\n",
    "    # print(\"model:\", model_name)\n",
    "    \n",
    "    ## Train model for each of the 18 questions\n",
    "    for q_no in range(1, 19):\n",
    "        if q_no <= 3:\n",
    "            select = train[train['level_group'] == '0-4']\n",
    "        elif q_no <= 13:\n",
    "            select = train[train['level_group'] == '5-12']\n",
    "        else:\n",
    "            select = train[train['level_group'] == '13-22']\n",
    "\n",
    "        ## Create train and validation split\n",
    "        train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "        train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "        validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "        train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        train_y = train_y['correct']\n",
    "\n",
    "        validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        validate_y = validate_y['correct']\n",
    "\n",
    "        ## Instantiate the model\n",
    "        model = model_type\n",
    "\n",
    "        ## If boolean random_search is true\n",
    "        if random_search:\n",
    "            ## Create the RandomizedSearchCV object\n",
    "            rs = RandomizedSearchCV(model, hyperparams, n_iter=20, cv=3, scoring='f1', n_jobs=-1, verbose=0, random_state=42)\n",
    "\n",
    "            ## Fit the RandomizedSearchCV object to the data\n",
    "            rs.fit(train_X, train_y)\n",
    "\n",
    "            ## Obtain the best scoring hyperparameters\n",
    "            best_params = rs.best_params_\n",
    "            best_params_list.append(best_params)\n",
    "\n",
    "            ## Uncomment if you want to see the best parameters for each question\n",
    "            print(\"Best hyperparameters for question\", q_no, \":\", best_params)\n",
    "\n",
    "            ## Get the best estimator\n",
    "            model = rs.best_estimator_\n",
    "            \n",
    "        model.fit(train_X, train_y)\n",
    "\n",
    "        if model_name in stored_models:\n",
    "            stored_models[model_name].append(pickle.dumps(model))\n",
    "        else:\n",
    "            stored_models[model_name] = [pickle.dumps(model)]\n",
    "\n",
    "        ## Calculate the accuracy and F1 score using cross_val_score\n",
    "        question_acc = np.mean(cross_val_score(model, validate_X, validate_y, cv=5))\n",
    "        question_f1 = np.mean(cross_val_score(model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "        overall_acc += question_acc\n",
    "        overall_f1 += question_f1\n",
    "        print(\"Question\", q_no, \"accuracy:\", question_acc, \"F1 score:\", question_f1)\n",
    "\n",
    "    overall_acc /= 18\n",
    "    overall_f1 /= 18\n",
    "    print(\"Overall accuracy:\", overall_acc)\n",
    "    print(\"Overall F1 score:\", overall_f1)\n",
    "\n",
    "    ## If randomize search executed return best params else return null\n",
    "    return best_params_list if random_search else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'subsample': 1, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 1}\n",
      "Question 1 accuracy: 0.7273500347853105 f1: 0.8420765776953882\n",
      "Best hyperparameters for question 2: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "Question 2 accuracy: 0.980267610485576 f1: 0.9900354266090516\n",
      "Best hyperparameters for question 3: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 3 accuracy: 0.9359220809045532 f1: 0.9669005007379587\n",
      "Best hyperparameters for question 4: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 1}\n",
      "Question 4 accuracy: 0.7901545188257199 f1: 0.8827222850315637\n",
      "Best hyperparameters for question 5: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 5 accuracy: 0.5289623170393986 f1: 0.6603053272506263\n",
      "Best hyperparameters for question 6: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 6 accuracy: 0.7793341483677921 f1: 0.8758947750071627\n",
      "Best hyperparameters for question 7: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 7 accuracy: 0.7292595119249448 f1: 0.8434355357170306\n",
      "Best hyperparameters for question 8: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 8 accuracy: 0.6072547072742951 f1: 0.7538128830629411\n",
      "Best hyperparameters for question 9: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 9 accuracy: 0.733078691351854 f1: 0.8459840361927228\n",
      "Best hyperparameters for question 10: {'subsample': 1, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.2, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 10 accuracy: 0.5215382987393984 f1: 0.531874648190831\n",
      "Best hyperparameters for question 11: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 11 accuracy: 0.6367497236312711 f1: 0.7776026493909391\n",
      "Best hyperparameters for question 12: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 12 accuracy: 0.8661150549472817 f1: 0.9282546716439211\n",
      "Best hyperparameters for question 13: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 13 accuracy: 0.7197116759314921 f1: 0.004511405237961137\n",
      "Best hyperparameters for question 14: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 14 accuracy: 0.7071932419684208 f1: 0.8284854693053862\n",
      "Best hyperparameters for question 15: {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 15 accuracy: 0.5134665306774918 f1: 0.4460885847114177\n",
      "Best hyperparameters for question 16: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 16 accuracy: 0.7313813032896321 f1: 0.8448528946124784\n",
      "Best hyperparameters for question 17: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1}\n",
      "Question 17 accuracy: 0.687248313081303 f1: 0.8145903557279013\n",
      "Best hyperparameters for question 18: {'subsample': 1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1}\n",
      "Question 18 accuracy: 0.9537452184269835 f1: 0.97632500393675\n",
      "Overall accuracy: 0.7304851656473733 Overall f1: 0.7674307238923351\n"
     ]
    }
   ],
   "source": [
    "########## XGBoost ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'XGBoost', \n",
    "    XGBClassifier(eval_metric='error', use_label_encoder=False), \n",
    "    params, \n",
    "    True)\n",
    "\n",
    "if res:\n",
    "    best_params_dict['XGBoost'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 12, 'min_samples_split': 8, 'n_estimators': 237}\n",
      "Question 1 accuracy: 0.7235308553584012 f1: 0.8395913603637742\n",
      "Best hyperparameters for question 2: {'criterion': 'entropy', 'max_depth': 37, 'min_samples_leaf': 11, 'min_samples_split': 12, 'n_estimators': 312}\n",
      "Question 2 accuracy: 0.9779335048958353 f1: 0.9888436167402521\n",
      "Best hyperparameters for question 3: {'criterion': 'gini', 'max_depth': 29, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 135}\n",
      "Question 3 accuracy: 0.9310417806476596 f1: 0.9642896281516811\n",
      "Best hyperparameters for question 4: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 351}\n",
      "Question 4 accuracy: 0.8016127325493694 f1: 0.8900139804255083\n",
      "Best hyperparameters for question 5: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 19, 'min_samples_split': 7, 'n_estimators': 331}\n",
      "Question 5 accuracy: 0.5429683014636848 f1: 0.687276776257302\n",
      "Best hyperparameters for question 6: {'criterion': 'entropy', 'max_depth': 39, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 296}\n",
      "Question 6 accuracy: 0.7699981763041115 f1: 0.8698878181087849\n",
      "Best hyperparameters for question 7: {'criterion': 'entropy', 'max_depth': 37, 'min_samples_leaf': 17, 'min_samples_split': 7, 'n_estimators': 357}\n",
      "Question 7 accuracy: 0.7445364547802221 f1: 0.8535636047178434\n",
      "Best hyperparameters for question 8: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_leaf': 13, 'min_samples_split': 19, 'n_estimators': 298}\n",
      "Question 8 accuracy: 0.6252919602029031 f1: 0.7693896805507003\n",
      "Best hyperparameters for question 9: {'criterion': 'gini', 'max_depth': 34, 'min_samples_leaf': 3, 'min_samples_split': 19, 'n_estimators': 175}\n",
      "Question 9 accuracy: 0.7349886187867695 f1: 0.8471131489004614\n",
      "Best hyperparameters for question 10: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 363}\n",
      "Question 10 accuracy: 0.494371083838227 f1: 0.4896654010932213\n",
      "Best hyperparameters for question 11: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 18, 'min_samples_split': 4, 'n_estimators': 138}\n",
      "Question 11 accuracy: 0.6490558433692895 f1: 0.7871299165689236\n",
      "Best hyperparameters for question 12: {'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 7, 'min_samples_split': 12, 'n_estimators': 147}\n",
      "Question 12 accuracy: 0.8676003539320909 f1: 0.9291070322823932\n",
      "Best hyperparameters for question 13: {'criterion': 'gini', 'max_depth': 17, 'min_samples_leaf': 3, 'min_samples_split': 19, 'n_estimators': 388}\n",
      "Question 13 accuracy: 0.736049064173832 f1: 0.0015999999999999996\n",
      "Best hyperparameters for question 14: {'criterion': 'entropy', 'max_depth': 31, 'min_samples_leaf': 13, 'min_samples_split': 5, 'n_estimators': 144}\n",
      "Question 14 accuracy: 0.7059198069133833 f1: 0.8277576776246555\n",
      "Best hyperparameters for question 15: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 19, 'n_estimators': 433}\n",
      "Question 15 accuracy: 0.5132560176335633 f1: 0.22965432898860919\n",
      "Best hyperparameters for question 16: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 212}\n",
      "Question 16 accuracy: 0.735200707864182 f1: 0.8473955272425473\n",
      "Best hyperparameters for question 17: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 17, 'min_samples_split': 17, 'n_estimators': 241}\n",
      "Question 17 accuracy: 0.6863995064763719 f1: 0.8140413455715592\n",
      "Best hyperparameters for question 18: {'criterion': 'gini', 'max_depth': 21, 'min_samples_leaf': 9, 'min_samples_split': 11, 'n_estimators': 286}\n",
      "Question 18 accuracy: 0.9501379029298462 f1: 0.974431501819141\n",
      "Overall accuracy: 0.7327718151177636 Overall f1: 0.7561529080781865\n"
     ]
    }
   ],
   "source": [
    "########## RandomForest ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(1, 50),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'RandomForest', \n",
    "    RandomForestClassifier(), \n",
    "    params, \n",
    "    True)\n",
    "\n",
    "if res:\n",
    "    best_params_dict['RandomForest'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 300, 'depth': 3}\n",
      "Question 1 accuracy: 0.7315933923670446 f1: 0.8449944300999128\n",
      "Best hyperparameters for question 2: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 100, 'depth': 8}\n",
      "Question 2 accuracy: 0.978357908198301 f1: 0.9890605103363157\n",
      "Best hyperparameters for question 3: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 8}\n",
      "Question 3 accuracy: 0.932739393857522 f1: 0.9651992717529035\n",
      "Best hyperparameters for question 4: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 300, 'depth': 6}\n",
      "Question 4 accuracy: 0.8026734030840725 f1: 0.8905366867595094\n",
      "Best hyperparameters for question 5: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 4}\n",
      "Question 5 accuracy: 0.5503941209448097 f1: 0.7075917013795741\n",
      "Best hyperparameters for question 6: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 100, 'depth': 4}\n",
      "Question 6 accuracy: 0.7727562349010363 f1: 0.871813248765541\n",
      "Best hyperparameters for question 7: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 6}\n",
      "Question 7 accuracy: 0.7394442905935567 f1: 0.8502074435631481\n",
      "Best hyperparameters for question 8: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 700, 'depth': 3}\n",
      "Question 8 accuracy: 0.6242308393729188 f1: 0.7686478636047195\n",
      "Best hyperparameters for question 9: {'verbose': 0, 'learning_rate': 0.1, 'iterations': 100, 'depth': 4}\n",
      "Question 9 accuracy: 0.7339272728091446 f1: 0.846511121438812\n",
      "Best hyperparameters for question 10: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 100, 'depth': 4}\n",
      "Question 10 accuracy: 0.4854613162581362 f1: 0.4763551075098283\n",
      "Best hyperparameters for question 11: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 300, 'depth': 3}\n",
      "Question 11 accuracy: 0.6303847998324901 f1: 0.7725247709830152\n",
      "Best hyperparameters for question 12: {'verbose': 0, 'learning_rate': 0.1, 'iterations': 100, 'depth': 3}\n",
      "Question 12 accuracy: 0.8676003539320909 f1: 0.9291070322823932\n",
      "Best hyperparameters for question 13: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 700, 'depth': 6}\n",
      "Question 13 accuracy: 0.7186505551015079 f1: 0.0\n",
      "Best hyperparameters for question 14: {'verbose': 0, 'learning_rate': 0.05, 'iterations': 100, 'depth': 4}\n",
      "Question 14 accuracy: 0.7067686135183147 f1: 0.8281949216891658\n",
      "Best hyperparameters for question 15: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 6}\n",
      "Question 15 accuracy: 0.4988330597789501 f1: 0.3950397696801813\n",
      "Best hyperparameters for question 16: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 500, 'depth': 4}\n",
      "Question 16 accuracy: 0.7358369750964195 f1: 0.8478180605605466\n",
      "Best hyperparameters for question 17: {'verbose': 0, 'learning_rate': 0.01, 'iterations': 700, 'depth': 4}\n",
      "Question 17 accuracy: 0.690006371678228 f1: 0.8165724469216922\n",
      "Best hyperparameters for question 18: {'verbose': 0, 'learning_rate': 0.2, 'iterations': 100, 'depth': 3}\n",
      "Question 18 accuracy: 0.9450457387431808 f1: 0.971746500349014\n",
      "Overall accuracy: 0.7302613688926513 Overall f1: 0.7651067159820151\n"
     ]
    }
   ],
   "source": [
    "########## CatBoost ##########\n",
    "\n",
    "## Load alternate train data for catboost\n",
    "cat_train = pd.read_csv('cat_train_preprocessed.csv')\n",
    "cat_train['session_id'] = cat_train['session_id'].astype(str)\n",
    "\n",
    "# Specify the categorical columns to be used by the CatBoost model\n",
    "cat_features = ['event_name_mode', 'fqid_mode', 'room_fqid_mode', 'text_mode']\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'iterations': [100, 300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'depth': [3, 4, 6, 8],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    cat_train, \n",
    "    labels, \n",
    "    'CatBoost', \n",
    "    CatBoostClassifier(cat_features=cat_features, verbose=0), \n",
    "    params, \n",
    "    True)\n",
    "\n",
    "## Add best hyperparameters to dictionary\n",
    "if res:\n",
    "    best_params_dict['CatBoost'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for question 1: {'subsample': 0.8, 'n_estimators': 200, 'min_child_samples': 20, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 1 accuracy: 0.72501592919557 f1: 0.8404331703415556\n",
      "Best hyperparameters for question 2: {'subsample': 1, 'n_estimators': 500, 'min_child_samples': 10, 'max_depth': 10, 'learning_rate': 0.2, 'colsample_bytree': 0.8}\n",
      "Question 2 accuracy: 0.9794188038806448 f1: 0.9896023367008606\n",
      "Best hyperparameters for question 3: {'subsample': 0.8, 'n_estimators': 200, 'min_child_samples': 30, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 3 accuracy: 0.9374071547417218 f1: 0.967692466878107\n",
      "Best hyperparameters for question 4: {'subsample': 1, 'n_estimators': 100, 'min_child_samples': 10, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1}\n",
      "Question 4 accuracy: 0.802037135851835 f1: 0.8901188324594734\n",
      "Best hyperparameters for question 5: {'subsample': 0.8, 'n_estimators': 200, 'min_child_samples': 30, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 5 accuracy: 0.5295979088287144 f1: 0.6767883419485032\n",
      "Best hyperparameters for question 6: {'subsample': 0.8, 'n_estimators': 500, 'min_child_samples': 30, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 6 accuracy: 0.7666024995891056 f1: 0.8677559488115303\n",
      "Best hyperparameters for question 7: {'subsample': 1, 'n_estimators': 200, 'min_child_samples': 20, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 7 accuracy: 0.7451729471601002 f1: 0.8539459258697496\n",
      "Best hyperparameters for question 8: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 30, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 8 accuracy: 0.606620241223182 f1: 0.753914354201281\n",
      "Best hyperparameters for question 9: {'subsample': 0.8, 'n_estimators': 200, 'min_child_samples': 20, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 9 accuracy: 0.7318057065920978 f1: 0.8449838983088409\n",
      "Best hyperparameters for question 10: {'subsample': 0.8, 'n_estimators': 200, 'min_child_samples': 30, 'max_depth': 10, 'learning_rate': 0.2, 'colsample_bytree': 1}\n",
      "Question 10 accuracy: 0.4933178431756625 f1: 0.515872758822885\n",
      "Best hyperparameters for question 11: {'subsample': 0.8, 'n_estimators': 200, 'min_child_samples': 10, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 11 accuracy: 0.6337800262522149 f1: 0.7756674093124832\n",
      "Best hyperparameters for question 12: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 30, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "Question 12 accuracy: 0.8580522927909977 f1: 0.9236039840806651\n",
      "Best hyperparameters for question 13: {'subsample': 0.8, 'n_estimators': 200, 'min_child_samples': 30, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 13 accuracy: 0.7248036149705169 f1: 0.0\n",
      "Best hyperparameters for question 14: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 10, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 14 accuracy: 0.7139827942173079 f1: 0.8330029676828351\n",
      "Best hyperparameters for question 15: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 10, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Question 15 accuracy: 0.48906908205055466 f1: 0.32033217924733065\n",
      "Best hyperparameters for question 16: {'subsample': 0.8, 'n_estimators': 200, 'min_child_samples': 20, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 16 accuracy: 0.7313813032896321 f1: 0.8448528946124784\n",
      "Best hyperparameters for question 17: {'subsample': 0.8, 'n_estimators': 100, 'min_child_samples': 10, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Question 17 accuracy: 0.6832168194293408 f1: 0.8117514444848728\n",
      "Best hyperparameters for question 18: {'subsample': 0.8, 'n_estimators': 500, 'min_child_samples': 20, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 1}\n",
      "Question 18 accuracy: 0.9511990237598305 f1: 0.9749891215656898\n",
      "Overall accuracy: 0.7279156181666129 Overall f1: 0.7602948908516189\n"
     ]
    }
   ],
   "source": [
    "########## LightGBM ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'LightGBM', \n",
    "    LGBMClassifier(), \n",
    "    params, \n",
    "    True)\n",
    "\n",
    "if res:\n",
    "    best_params_dict['LightGBM'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 accuracy: 0.7254402715892213 F1 score: 0.8408755533694049\n",
      "Question 2 accuracy: 0.9813282410354339 F1 score: 0.990576140501178\n",
      "Question 3 accuracy: 0.9329514109908763 F1 score: 0.9653128430296377\n",
      "Question 4 accuracy: 0.7937619350732018 F1 score: 0.8850248403122781\n",
      "Question 5 accuracy: 0.5461489497135582 F1 score: 0.7064635652531907\n",
      "Question 6 accuracy: 0.7721196690006366 F1 score: 0.8714080459770115\n",
      "Question 7 accuracy: 0.7307447485677913 F1 score: 0.8444280985656492\n",
      "Question 8 accuracy: 0.61001485253554 F1 score: 0.7577754348972061\n",
      "Question 9 accuracy: 0.7362614046255039 F1 score: 0.8480997189294879\n",
      "Question 10 accuracy: 0.5077445363887121 F1 score: 0.5387673956262427\n",
      "Question 11 accuracy: 0.6397199236155315 F1 score: 0.7802795031055901\n",
      "Question 12 accuracy: 0.862295777636325 F1 score: 0.9260567392047396\n",
      "Question 13 accuracy: 0.7383831954169319 F1 score: 0.0\n",
      "Question 14 accuracy: 0.7158922130277955 F1 score: 0.834425621367627\n",
      "Question 15 accuracy: 0.5138977296838532 F1 score: 0.011221406991799743\n",
      "Question 16 accuracy: 0.7209845109272226 F1 score: 0.8378744914313895\n",
      "Question 17 accuracy: 0.6870358582643752 F1 score: 0.8144887435542699\n",
      "Question 18 accuracy: 0.9511988117971568 F1 score: 0.974989125706829\n",
      "Overall accuracy: 0.7314402244383147 Overall F1 score: 0.7460037371013071\n"
     ]
    }
   ],
   "source": [
    "## Train ensemble with final estimator\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "## Initialize vars to store model scores\n",
    "overall_acc, overall_f1 = 0, 0\n",
    "\n",
    "## Train model for each of the 18 questions\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "        cat_select = cat_train[cat_train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "        cat_select = cat_train[cat_train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "        cat_select = cat_train[cat_train['level_group'] == '13-22']\n",
    "\n",
    "    ## Create train and validation splits\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    cat_train_X, cat_validate_X = train_test_split(cat_select, test_size=0.2)\n",
    "\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    cat_train_X = cat_train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    cat_validate_X = cat_validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    ## Train the four models with the optimized hyperparameters\n",
    "    xgb_model = XGBClassifier(**best_params_dict['XGBoost'][q_no - 1]).fit(train_X, train_y)\n",
    "    rf_model = RandomForestClassifier(**best_params_dict['RandomForest'][q_no - 1]).fit(train_X, train_y)\n",
    "    cat_model = CatBoostClassifier(**best_params_dict['CatBoost'][q_no - 1], cat_features=cat_features).fit(cat_train_X, train_y)\n",
    "    lgbm_model = LGBMClassifier(**best_params_dict['LightGBM'][q_no - 1]).fit(train_X, train_y)\n",
    "\n",
    "    ## Obtain the predicted probabilities for each class for each model\n",
    "    rf_pred = rf_model.predict_proba(validate_X)[:, 1]\n",
    "    xgb_pred = xgb_model.predict_proba(validate_X)[:, 1]\n",
    "    cat_pred = cat_model.predict_proba(cat_validate_X)[:, 1]\n",
    "    lgbm_pred = lgbm_model.predict_proba(validate_X)[:, 1]\n",
    "\n",
    "    ## Stack the predictions\n",
    "    stacked_predictions = np.column_stack((xgb_pred, rf_pred, cat_pred, lgbm_pred))\n",
    "\n",
    "    ## Train the final_estimator\n",
    "    final_estimator.fit(stacked_predictions, validate_y)\n",
    "\n",
    "    ## Use the final_estimator to make the final prediction\n",
    "    ensemble_pred = final_estimator.predict(stacked_predictions)\n",
    "    \n",
    "    model_name = 'ensemble_' + str(final_estimator)\n",
    "    if model_name in stored_models:\n",
    "        stored_models[model_name].append(pickle.dumps(final_estimator))\n",
    "    else:\n",
    "        stored_models[model_name] = [pickle.dumps(final_estimator)]\n",
    "\n",
    "    ## Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_acc = np.mean(ensemble_pred == validate_y)\n",
    "    question_f1 = f1_score(validate_y, ensemble_pred)\n",
    "    overall_acc += question_acc\n",
    "    overall_f1 += question_f1\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_acc, \"F1 score:\", question_f1)\n",
    "\n",
    "    print(\"Overall accuracy:\", overall_acc)\n",
    "    print(\"Overall F1 score:\", overall_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 accuracy: 0.7504774029280713 F1 score: 0.8535491905354919\n",
      "Question 2 accuracy: 0.9838743899851474 F1 score: 0.9918507398670383\n",
      "Question 3 accuracy: 0.9352853808614471 F1 score: 0.966398589842459\n",
      "Question 4 accuracy: 0.8014003819223424 F1 score: 0.8882521489971347\n",
      "Question 5 accuracy: 0.571398260131551 F1 score: 0.7083453652902107\n",
      "Question 6 accuracy: 0.7829408020369192 F1 score: 0.8775583482944345\n",
      "Question 7 accuracy: 0.7555697008274984 F1 score: 0.8573551263001485\n",
      "Question 8 accuracy: 0.6437513261192447 F1 score: 0.7768770764119601\n",
      "Question 9 accuracy: 0.7523870146403565 F1 score: 0.8535575354498683\n",
      "Question 10 accuracy: 0.5465733078718439 F1 score: 0.4078692158492657\n",
      "Question 11 accuracy: 0.6643326967960959 F1 score: 0.7896276595744681\n",
      "Question 12 accuracy: 0.8703585826437513 F1 score: 0.9300515168860906\n",
      "Question 13 accuracy: 0.7407171652875026 F1 score: 0.11449275362318839\n",
      "Question 14 accuracy: 0.728835136855506 F1 score: 0.8375699034062023\n",
      "Question 15 accuracy: 0.5690642902609803 F1 score: 0.6050943029360295\n",
      "Question 16 accuracy: 0.7489921493740718 F1 score: 0.853824292598542\n",
      "Question 17 accuracy: 0.7033736473583705 F1 score: 0.8219108280254778\n",
      "Question 18 accuracy: 0.9543814979842987 F1 score: 0.9765616483157091\n",
      "Overall accuracy: 0.7502062852158333 Overall F1 score: 0.7839303467890955\n"
     ]
    }
   ],
   "source": [
    "## Train ensemble with final estimator\n",
    "final_estimator = DecisionTreeClassifier(max_depth=7)\n",
    "\n",
    "## Initialize vars to store model scores\n",
    "overall_acc, overall_f1 = 0, 0\n",
    "\n",
    "## Train model for each of the 18 questions\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select = train[train['level_group'] == '0-4']\n",
    "        cat_select = cat_train[cat_train['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = train[train['level_group'] == '5-12']\n",
    "        cat_select = cat_train[cat_train['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = train[train['level_group'] == '13-22']\n",
    "        cat_select = cat_train[cat_train['level_group'] == '13-22']\n",
    "\n",
    "    ## Create train and validation splits\n",
    "    train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "    cat_train_X, cat_validate_X = train_test_split(cat_select, test_size=0.2)\n",
    "\n",
    "    train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "    validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "    train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    cat_train_X = cat_train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    train_y = train_y['correct']\n",
    "\n",
    "    validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    cat_validate_X = cat_validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "    validate_y = validate_y['correct']\n",
    "\n",
    "    ## Train the four models with the optimized hyperparameters\n",
    "    xgb_model = XGBClassifier(**best_params_dict['XGBoost'][q_no - 1]).fit(train_X, train_y)\n",
    "    rf_model = RandomForestClassifier(**best_params_dict['RandomForest'][q_no - 1]).fit(train_X, train_y)\n",
    "    cat_model = CatBoostClassifier(**best_params_dict['CatBoost'][q_no - 1], cat_features=cat_features).fit(cat_train_X, train_y)\n",
    "    lgbm_model = LGBMClassifier(**best_params_dict['LightGBM'][q_no - 1]).fit(train_X, train_y)\n",
    "\n",
    "    ## Obtain the predicted probabilities for each class for each model\n",
    "    rf_pred = rf_model.predict_proba(validate_X)[:, 1]\n",
    "    xgb_pred = xgb_model.predict_proba(validate_X)[:, 1]\n",
    "    cat_pred = cat_model.predict_proba(cat_validate_X)[:, 1]\n",
    "    lgbm_pred = lgbm_model.predict_proba(validate_X)[:, 1]\n",
    "\n",
    "    ## Stack the predictions\n",
    "    stacked_predictions = np.column_stack((xgb_pred, rf_pred, cat_pred, lgbm_pred))\n",
    "\n",
    "    ## Train the final_estimator\n",
    "    final_estimator.fit(stacked_predictions, validate_y)\n",
    "\n",
    "    ## Use the final_estimator to make the final prediction\n",
    "    ensemble_pred = final_estimator.predict(stacked_predictions)\n",
    "    \n",
    "    model_name = 'ensemble_' + str(final_estimator)\n",
    "    if model_name in stored_models:\n",
    "        stored_models[model_name].append(pickle.dumps(final_estimator))\n",
    "    else:\n",
    "        stored_models[model_name] = [pickle.dumps(final_estimator)]\n",
    "\n",
    "    ## Calculate the accuracy and F1 score using cross_val_score\n",
    "    question_acc = np.mean(ensemble_pred == validate_y)\n",
    "    question_f1 = f1_score(validate_y, ensemble_pred)\n",
    "    overall_acc += question_acc\n",
    "    overall_f1 += question_f1\n",
    "    print(\"Question\", q_no, \"accuracy:\", question_acc, \"F1 score:\", question_f1)\n",
    "\n",
    "    print(\"Overall accuracy:\", overall_acc)\n",
    "    print(\"Overall F1 score:\", overall_f1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
