{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import pickle\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training data\n",
    "train = pd.read_csv('train_preprocessed.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]))\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]))\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize dictionaries to store models and best parameters for each question for each model type\n",
    "stored_models = {}\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to train models and evaluate on validation data\n",
    "def train_model(train, labels, model_name, model_type, hyperparams, random_search):\n",
    "    ## Initialize vars to store model scores\n",
    "    overall_acc, overall_f1 = 0, 0\n",
    "\n",
    "    ## Initialize array to store best parameters for each question model\n",
    "    best_params_list = []\n",
    "\n",
    "    ## Print model name\n",
    "    print(\"model:\", model_name)\n",
    "    \n",
    "    ## Train model for each of the 18 questions\n",
    "    for q_no in range(1, 19):\n",
    "        if q_no <= 3:\n",
    "            select = train[train['level_group'] == '0-4']\n",
    "        elif q_no <= 13:\n",
    "            select = train[train['level_group'] == '5-12']\n",
    "        else:\n",
    "            select = train[train['level_group'] == '13-22']\n",
    "\n",
    "        ## Create train and validation split\n",
    "        train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "        train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "        validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "        train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        train_y = train_y['correct']\n",
    "\n",
    "        validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        validate_y = validate_y['correct']\n",
    "\n",
    "        ## Instantiate the model\n",
    "        model = model_type\n",
    "\n",
    "        ## If boolean random_search is true\n",
    "        if random_search:\n",
    "            ## Create the RandomizedSearchCV object\n",
    "            rs = RandomizedSearchCV(model, hyperparams, n_iter=20, cv=3, scoring='f1', n_jobs=-1, verbose=0, random_state=42)\n",
    "\n",
    "            ## Fit the RandomizedSearchCV object to the data\n",
    "            rs.fit(train_X, train_y)\n",
    "\n",
    "            ## Obtain the best scoring hyperparameters\n",
    "            best_params = rs.best_params_\n",
    "            best_params_list.append(best_params)\n",
    "            # print(\"Best hyperparameters for question\", q_no, \":\", best_params)\n",
    "\n",
    "            ## Get the best estimator\n",
    "            model = rs.best_estimator_\n",
    "            \n",
    "        model.fit(train_X, train_y)\n",
    "\n",
    "        if model_name in stored_models:\n",
    "            stored_models[model_name].append(pickle.dumps(model))\n",
    "        else:\n",
    "            stored_models[model_name] = [pickle.dumps(model)]\n",
    "\n",
    "        ## Calculate the accuracy and F1 score using cross_val_score\n",
    "        question_acc = np.mean(cross_val_score(model, validate_X, validate_y, cv=5))\n",
    "        question_f1 = np.mean(cross_val_score(model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "        overall_acc += question_acc\n",
    "        overall_f1 += question_f1\n",
    "        print(\"Question\", q_no, \"accuracy:\", question_acc, \"f1:\", question_f1)\n",
    "\n",
    "    overall_acc /= 18\n",
    "    overall_f1 /= 18\n",
    "    print(\"Overall accuracy:\", overall_acc)\n",
    "    print(\"Overall F1 score:\", overall_f1)\n",
    "\n",
    "    ## If randomize search executed return best params else return null\n",
    "    return best_params_list if random_search else None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: XGBoost\n",
      "Question 1 accuracy: 0.6993400922655031 f1: 0.8167079288085439\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.01\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m100\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m500\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcolsample_bytree\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.8\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m## Set last argument to true if want to carry out randomized search for best hyperparams\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m res \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     labels, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mXGBoost\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     XGBClassifier(eval_metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39merror\u001b[39;49m\u001b[39m'\u001b[39;49m, use_label_encoder\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     params,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mFalse\u001b[39;49;00m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m res:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     best_params_dict[\u001b[39m'\u001b[39m\u001b[39mXGBoost\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m res\n",
      "\u001b[1;32m/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb Cell 5\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train, labels, model_name, model_type, hyperparams, random_search)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m## Calculate the accuracy and F1 score using cross_val_score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m question_acc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cross_val_score(model, validate_X, validate_y, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m question_f1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cross_val_score(model, validate_X, validate_y, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m overall_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m question_acc\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W4sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m overall_f1 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m question_f1\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    507\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 509\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    510\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    511\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    512\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    513\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    514\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    515\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    516\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    517\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    518\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    519\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    520\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    521\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 267\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    268\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m         clone(estimator),\n\u001b[1;32m    270\u001b[0m         X,\n\u001b[1;32m    271\u001b[0m         y,\n\u001b[1;32m    272\u001b[0m         scorers,\n\u001b[1;32m    273\u001b[0m         train,\n\u001b[1;32m    274\u001b[0m         test,\n\u001b[1;32m    275\u001b[0m         verbose,\n\u001b[1;32m    276\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    277\u001b[0m         fit_params,\n\u001b[1;32m    278\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    279\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    280\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    281\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[1;32m    288\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########## XGBoost ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'XGBoost', \n",
    "    XGBClassifier(eval_metric='error', use_label_encoder=False), \n",
    "    params,\n",
    "    False )\n",
    "\n",
    "if res:\n",
    "    best_params_dict['XGBoost'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: RandomForest\n",
      "Question 1 accuracy: 0.7307439103191918 f1: 0.8441748667486753\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: randint(\u001b[39m100\u001b[39m, \u001b[39m500\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: randint(\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcriterion\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mgini\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m## Set last argument to true if want to carry out randomized search for best hyperparams\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m res \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     labels, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mRandomForest\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     RandomForestClassifier(), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     params, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m res:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     best_params_dict[\u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m res\n",
      "\u001b[1;32m/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb Cell 6\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train, labels, model_name, model_type, hyperparams, random_search)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m# print(\"Best hyperparameters for question\", q_no, \":\", best_params)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m## Get the best estimator\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     model \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_X, train_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39min\u001b[39;00m stored_models:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W5sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     stored_models[model_name]\u001b[39m.\u001b[39mappend(pickle\u001b[39m.\u001b[39mdumps(model))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    442\u001b[0m ]\n\u001b[1;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    454\u001b[0m )(\n\u001b[1;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    456\u001b[0m         t,\n\u001b[1;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    458\u001b[0m         X,\n\u001b[1;32m    459\u001b[0m         y,\n\u001b[1;32m    460\u001b[0m         sample_weight,\n\u001b[1;32m    461\u001b[0m         i,\n\u001b[1;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    468\u001b[0m )\n\u001b[1;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/tree/_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    900\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m ):\n\u001b[1;32m    902\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    938\u001b[0m         X,\n\u001b[1;32m    939\u001b[0m         y,\n\u001b[1;32m    940\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    941\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    942\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########## RandomForest ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(1, 50),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'RandomForest', \n",
    "    RandomForestClassifier(), \n",
    "    params, \n",
    "    False)\n",
    "\n",
    "if res:\n",
    "    best_params_dict['RandomForest'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: CatBoost\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Labels variable is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39miterations\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m100\u001b[39m, \u001b[39m300\u001b[39m, \u001b[39m500\u001b[39m, \u001b[39m700\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.01\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdepth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m8\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m## Set last argument to true if want to carry out randomized search for best hyperparams\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m res \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     cat_train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     labels, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mCatBoost\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     CatBoostClassifier(cat_features\u001b[39m=\u001b[39;49mcat_features), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     params, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m## Add best hyperparameters to dictionary\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mif\u001b[39;00m res:\n",
      "\u001b[1;32m/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb Cell 7\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train, labels, model_name, model_type, hyperparams, random_search)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m# print(\"Best hyperparameters for question\", q_no, \":\", best_params)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m## Get the best estimator\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     model \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_X, train_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39min\u001b[39;00m stored_models:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#W6sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     stored_models[model_name]\u001b[39m.\u001b[39mappend(pickle\u001b[39m.\u001b[39mdumps(model))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/catboost/core.py:5128\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5126\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5128\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[1;32m   5129\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[1;32m   5130\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   5131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/catboost/core.py:2339\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, PATH_TYPES \u001b[39m+\u001b[39m (Pool,)):\n\u001b[1;32m   2337\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2339\u001b[0m train_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_train_params(\n\u001b[1;32m   2340\u001b[0m     X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, cat_features\u001b[39m=\u001b[39;49mcat_features, text_features\u001b[39m=\u001b[39;49mtext_features, embedding_features\u001b[39m=\u001b[39;49membedding_features,\n\u001b[1;32m   2341\u001b[0m     pairs\u001b[39m=\u001b[39;49mpairs, sample_weight\u001b[39m=\u001b[39;49msample_weight, group_id\u001b[39m=\u001b[39;49mgroup_id, group_weight\u001b[39m=\u001b[39;49mgroup_weight,\n\u001b[1;32m   2342\u001b[0m     subgroup_id\u001b[39m=\u001b[39;49msubgroup_id, pairs_weight\u001b[39m=\u001b[39;49mpairs_weight, baseline\u001b[39m=\u001b[39;49mbaseline, use_best_model\u001b[39m=\u001b[39;49muse_best_model,\n\u001b[1;32m   2343\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set, verbose\u001b[39m=\u001b[39;49mverbose, logging_level\u001b[39m=\u001b[39;49mlogging_level, plot\u001b[39m=\u001b[39;49mplot, plot_file\u001b[39m=\u001b[39;49mplot_file,\n\u001b[1;32m   2344\u001b[0m     column_description\u001b[39m=\u001b[39;49mcolumn_description, verbose_eval\u001b[39m=\u001b[39;49mverbose_eval, metric_period\u001b[39m=\u001b[39;49mmetric_period,\n\u001b[1;32m   2345\u001b[0m     silent\u001b[39m=\u001b[39;49msilent, early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds, save_snapshot\u001b[39m=\u001b[39;49msave_snapshot,\n\u001b[1;32m   2346\u001b[0m     snapshot_file\u001b[39m=\u001b[39;49msnapshot_file, snapshot_interval\u001b[39m=\u001b[39;49msnapshot_interval, init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[1;32m   2347\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[1;32m   2348\u001b[0m )\n\u001b[1;32m   2349\u001b[0m params \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2350\u001b[0m train_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mtrain_pool\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/catboost/core.py:2220\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2217\u001b[0m text_features \u001b[39m=\u001b[39m _process_feature_indices(text_features, X, params, \u001b[39m'\u001b[39m\u001b[39mtext_features\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2218\u001b[0m embedding_features \u001b[39m=\u001b[39m _process_feature_indices(embedding_features, X, params, \u001b[39m'\u001b[39m\u001b[39membedding_features\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2220\u001b[0m train_pool \u001b[39m=\u001b[39m _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[1;32m   2221\u001b[0m                                sample_weight, group_id, group_weight, subgroup_id, pairs_weight,\n\u001b[1;32m   2222\u001b[0m                                baseline, column_description)\n\u001b[1;32m   2223\u001b[0m \u001b[39mif\u001b[39;00m train_pool\u001b[39m.\u001b[39mis_empty_:\n\u001b[1;32m   2224\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39mX is empty.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/catboost/core.py:1438\u001b[0m, in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1437\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39my has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1438\u001b[0m     train_pool \u001b[39m=\u001b[39m Pool(X, y, cat_features\u001b[39m=\u001b[39;49mcat_features, text_features\u001b[39m=\u001b[39;49mtext_features, embedding_features\u001b[39m=\u001b[39;49membedding_features, pairs\u001b[39m=\u001b[39;49mpairs, weight\u001b[39m=\u001b[39;49msample_weight, group_id\u001b[39m=\u001b[39;49mgroup_id,\n\u001b[1;32m   1439\u001b[0m                       group_weight\u001b[39m=\u001b[39;49mgroup_weight, subgroup_id\u001b[39m=\u001b[39;49msubgroup_id, pairs_weight\u001b[39m=\u001b[39;49mpairs_weight, baseline\u001b[39m=\u001b[39;49mbaseline)\n\u001b[1;32m   1440\u001b[0m \u001b[39mreturn\u001b[39;00m train_pool\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/catboost/core.py:792\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[1;32m    787\u001b[0m             \u001b[39mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m    788\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    789\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mpython objects.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m             )\n\u001b[0;32m--> 792\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[1;32m    793\u001b[0m                    group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    794\u001b[0m \u001b[39msuper\u001b[39m(Pool, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/catboost/core.py:1363\u001b[0m, in \u001b[0;36mPool._init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1362\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_label_type(label)\n\u001b[0;32m-> 1363\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_label_empty(label)\n\u001b[1;32m   1364\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_if_pandas_to_numpy(label)\n\u001b[1;32m   1365\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39mshape(label)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/catboost/core.py:901\u001b[0m, in \u001b[0;36mPool._check_label_empty\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[39mCheck label is not empty.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(label) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39mLabels variable is empty.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Labels variable is empty."
     ]
    }
   ],
   "source": [
    "########## CatBoost ##########\n",
    "\n",
    "## Load alternate train data for catboost\n",
    "cat_train = pd.read_csv('cat_train_preprocessed.csv')\n",
    "\n",
    "# Specify the categorical columns to be used by the CatBoost model\n",
    "cat_features = ['event_name_mode', 'fqid_mode', 'room_fqid_mode', 'text_mode']\n",
    "\n",
    "# print(cat_train.head)\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'iterations': [100, 300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'depth': [3, 4, 6, 8],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    cat_train, \n",
    "    labels, \n",
    "    'CatBoost', \n",
    "    CatBoostClassifier(cat_features=cat_features), \n",
    "    params, \n",
    "    False)\n",
    "\n",
    "## Add best hyperparameters to dictionary\n",
    "if res:\n",
    "    best_params_dict['CatBoost'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LightGBM\n",
      "Question 1 accuracy: 0.7067697392565175 f1: 0.8255218247641374\n",
      "Question 2 accuracy: 0.9775091015933699 f1: 0.9886266068480498\n",
      "Question 3 accuracy: 0.933163572012347 f1: 0.9654263976409796\n",
      "Question 4 accuracy: 0.792700713492873 f1: 0.8839513024546605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.01\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m100\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m500\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcolsample_bytree\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.8\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m## Set last argument to true if want to carry out randomized search for best hyperparams\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m res \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     labels, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mLightGBM\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     LGBMClassifier(), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     params, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m res:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     best_params_dict[\u001b[39m'\u001b[39m\u001b[39mLightGBM\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m res\n",
      "\u001b[1;32m/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb Cell 8\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train, labels, model_name, model_type, hyperparams, random_search)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     stored_models[model_name] \u001b[39m=\u001b[39m [pickle\u001b[39m.\u001b[39mdumps(model)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m## Calculate the accuracy and F1 score using cross_val_score\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m question_acc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cross_val_score(model, validate_X, validate_y, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m question_f1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cross_val_score(model, validate_X, validate_y, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brodybarton/Documents/GitHub/student-performance-prediction/model_final.ipynb#X10sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m overall_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m question_acc\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    507\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 509\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    510\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    511\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    512\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    513\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    514\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    515\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    516\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    517\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    518\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    519\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    520\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    521\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 267\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    268\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m         clone(estimator),\n\u001b[1;32m    270\u001b[0m         X,\n\u001b[1;32m    271\u001b[0m         y,\n\u001b[1;32m    272\u001b[0m         scorers,\n\u001b[1;32m    273\u001b[0m         train,\n\u001b[1;32m    274\u001b[0m         test,\n\u001b[1;32m    275\u001b[0m         verbose,\n\u001b[1;32m    276\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    277\u001b[0m         fit_params,\n\u001b[1;32m    278\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    279\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    280\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    281\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[1;32m    288\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/lightgbm/sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m             valid_sets[i] \u001b[39m=\u001b[39m (valid_x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_le\u001b[39m.\u001b[39mtransform(valid_y))\n\u001b[0;32m--> 967\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, _y, sample_weight\u001b[39m=\u001b[39;49msample_weight, init_score\u001b[39m=\u001b[39;49minit_score, eval_set\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[1;32m    968\u001b[0m             eval_names\u001b[39m=\u001b[39;49meval_names, eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[1;32m    969\u001b[0m             eval_class_weight\u001b[39m=\u001b[39;49meval_class_weight, eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[1;32m    970\u001b[0m             eval_metric\u001b[39m=\u001b[39;49meval_metric, early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m    971\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose, feature_name\u001b[39m=\u001b[39;49mfeature_name, categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[1;32m    972\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks, init_model\u001b[39m=\u001b[39;49minit_model)\n\u001b[1;32m    973\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/lightgbm/sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    745\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[1;32m    746\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m    749\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    750\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[1;32m    751\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[1;32m    752\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[1;32m    753\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[1;32m    754\u001b[0m     fobj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fobj,\n\u001b[1;32m    755\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,\n\u001b[1;32m    756\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[1;32m    757\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m    758\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    761\u001b[0m \u001b[39mif\u001b[39;00m evals_result:\n\u001b[1;32m    762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/catboost_env/lib/python3.8/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########## LightGBM ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'LightGBM', \n",
    "    LGBMClassifier(), \n",
    "    params, \n",
    "    False)\n",
    "\n",
    "if res:\n",
    "    best_params_dict['LightGBM'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m q_no \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     12\u001b[0m     select \u001b[38;5;241m=\u001b[39m train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0-4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m     cat_select \u001b[38;5;241m=\u001b[39m \u001b[43mcat_train\u001b[49m[cat_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0-4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m q_no \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m13\u001b[39m:\n\u001b[1;32m     15\u001b[0m     select \u001b[38;5;241m=\u001b[39m train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5-12\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_train' is not defined"
     ]
    }
   ],
   "source": [
    "## Train ensemble with final estimators\n",
    "final_estimators = [LogisticRegression(), DecisionTreeClassifier(max_depth=7)]\n",
    "\n",
    "for final_estimator in final_estimators:\n",
    "\n",
    "    ## Print the final estimator being used for the ensemble\n",
    "    print(\"Final estimator:\", str(final_estimator))\n",
    "\n",
    "    ## Initialize vars to store model scores\n",
    "    overall_acc, overall_f1 = 0, 0\n",
    "\n",
    "    ## Train model for each of the 18 questions\n",
    "    for q_no in range(1, 19):\n",
    "        if q_no <= 3:\n",
    "            select = train[train['level_group'] == '0-4']\n",
    "            cat_select = cat_train[cat_train['level_group'] == '0-4']\n",
    "        elif q_no <= 13:\n",
    "            select = train[train['level_group'] == '5-12']\n",
    "            cat_select = cat_train[cat_train['level_group'] == '5-12']\n",
    "        else:\n",
    "            select = train[train['level_group'] == '13-22']\n",
    "            cat_select = cat_train[cat_train['level_group'] == '13-22']\n",
    "\n",
    "        ## Create train and validation splits\n",
    "        train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "        cat_train_X, cat_validate_X = train_test_split(cat_select, test_size=0.2)\n",
    "\n",
    "        train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "        validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "        train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        cat_train_X = cat_train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        train_y = train_y['correct']\n",
    "\n",
    "        validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        cat_validate_X = cat_validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        validate_y = validate_y['correct']\n",
    "\n",
    "        # Train the four models with the optimized hyperparameters\n",
    "        xgb_model = XGBClassifier(best_params_dict['XGBoost'][q_no - 1]).fit(train_X, train_y)\n",
    "        rf_model = RandomForestClassifier(best_params_dict['RandomForest'][q_no - 1]).fit(train_X, train_y)\n",
    "        cat_model = CatBoostClassifier(best_params_dict['CatBoost'][q_no - 1], cat_features=cat_features).fit(cat_train_X, train_y)\n",
    "        lgbm_model = LGBMClassifier(best_params_dict['LightGBM'][q_no - 1]).fit(train_X, train_y)\n",
    "\n",
    "        ## Obtain the predicted probabilities for each class for each model\n",
    "        rf_pred = rf_model.predict_proba(validate_X)[:, 1]\n",
    "        xgb_pred = xgb_model.predict_proba(validate_X)[:, 1]\n",
    "        cat_pred = cat_model.predict_proba(cat_validate_X)[:, 1]\n",
    "        lgbm_pred = lgbm_model.predict_proba(validate_X)[:, 1]\n",
    "\n",
    "        ## Stack the predictions\n",
    "        stacked_predictions = np.column_stack((xgb_pred, rf_pred, cat_pred, lgbm_pred))\n",
    "\n",
    "        ## Train the final_estimator\n",
    "        final_estimator.fit(stacked_predictions, validate_y)\n",
    "\n",
    "        ## Use the meta-learner to make the final prediction\n",
    "        ensemble_pred = final_estimator.predict(stacked_predictions)\n",
    "\n",
    "        ## Calculate the accuracy and F1 score using cross_val_score\n",
    "        question_acc = np.mean(ensemble_pred == validate_y)\n",
    "        question_f1 = f1_score(validate_y, ensemble_pred)\n",
    "        overall_acc += question_acc\n",
    "        overall_f1 += question_f1\n",
    "        print(\"Question\", q_no, \"accuracy:\", question_acc, \"f1:\", question_f1)\n",
    "\n",
    "    print(\"Overall accuracy:\", overall_acc)\n",
    "    print(\"Overall F1 score:\", overall_f1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_preprocessed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame()\n",
    "\n",
    "def append_qnum(col, qnum):\n",
    "    return str(col) + '_q' + str(qnum)\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select = test[test['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = test[test['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = test[test['level_group'] == '13-22']\n",
    "\n",
    "    session_id = select['session_id'].apply(append_qnum, qnum=q_no).tolist()\n",
    "    select = select.drop(['session_id','level_group'], axis=1)\n",
    "\n",
    "    model = pickle.loads(stored_models['XGBoost'][q_no-1])\n",
    "    pred = model.predict(select)\n",
    "    \n",
    "    df = pd.DataFrame({'session_id': session_id, 'correct': pred})\n",
    "    preds = pd.concat([preds, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds\n",
    "preds.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
