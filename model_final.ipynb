{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import pickle\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training data\n",
    "train = pd.read_csv('train_preprocessed.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]))\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]))\n",
    "\n",
    "train['session_id'] = train['session_id'].astype(str)\n",
    "labels['session'] = labels['session'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize dictionaries to store models and best parameters for each question for each model type\n",
    "stored_models = {}\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to train models and evaluate on validation data\n",
    "def train_model(train, labels, model_name, model_type, hyperparams, random_search):\n",
    "    ## Initialize vars to store model scores\n",
    "    overall_acc, overall_f1 = 0, 0\n",
    "\n",
    "    ## Initialize array to store best parameters for each question model\n",
    "    best_params_list = []\n",
    "\n",
    "    ## Print model name\n",
    "    print(\"model:\", model_name)\n",
    "    \n",
    "    ## Train model for each of the 18 questions\n",
    "    for q_no in range(1, 19):\n",
    "        if q_no <= 3:\n",
    "            select = train[train['level_group'] == '0-4']\n",
    "        elif q_no <= 13:\n",
    "            select = train[train['level_group'] == '5-12']\n",
    "        else:\n",
    "            select = train[train['level_group'] == '13-22']\n",
    "\n",
    "        ## Create train and validation split\n",
    "        train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "        train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "        validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "        train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        train_y = train_y['correct']\n",
    "\n",
    "        validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        validate_y = validate_y['correct']\n",
    "\n",
    "        ## Instantiate the model\n",
    "        model = model_type\n",
    "\n",
    "        ## If boolean random_search is true\n",
    "        if random_search:\n",
    "            ## Create the RandomizedSearchCV object\n",
    "            rs = RandomizedSearchCV(model, hyperparams, n_iter=20, cv=3, scoring='f1', n_jobs=-1, verbose=0, random_state=42)\n",
    "\n",
    "            ## Fit the RandomizedSearchCV object to the data\n",
    "            rs.fit(train_X, train_y)\n",
    "\n",
    "            ## Obtain the best scoring hyperparameters\n",
    "            best_params = random_search.best_params_\n",
    "            best_params_list.append(best_params)\n",
    "            # print(\"Best hyperparameters for question\", q_no, \":\", best_params)\n",
    "\n",
    "            ## Get the best estimator\n",
    "            model = random_search.best_estimator_\n",
    "            \n",
    "        model.fit(train_X, train_y)\n",
    "\n",
    "        if model_name in stored_models:\n",
    "            stored_models[model_name].append(pickle.dumps(model))\n",
    "        else:\n",
    "            stored_models[model_name] = [pickle.dumps(model)]\n",
    "\n",
    "        ## Calculate the accuracy and F1 score using cross_val_score\n",
    "        question_acc = np.mean(cross_val_score(model, validate_X, validate_y, cv=5))\n",
    "        question_f1 = np.mean(cross_val_score(model, validate_X, validate_y, cv=5, scoring='f1'))\n",
    "        overall_acc += question_acc\n",
    "        overall_f1 += question_f1\n",
    "        print(\"Question\", q_no, \"accuracy:\", question_acc, \"f1:\", question_f1)\n",
    "\n",
    "    overall_acc /= 18\n",
    "    overall_f1 /= 18\n",
    "    print(\"Overall accuracy:\", overall_acc)\n",
    "    print(\"Overall F1 score:\", overall_f1)\n",
    "\n",
    "    ## If randomize search executed return best params else return null\n",
    "    return best_params_list if random_search else None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: XGBoost\n",
      "Question 1 accuracy: 0.6851244953878506 f1: 0.8082134630470378\n",
      "Question 2 accuracy: 0.9789946257258197 f1: 0.9893856768072089\n",
      "Question 3 accuracy: 0.9374073798893626 f1: 0.9676924707543394\n",
      "Question 4 accuracy: 0.7801827298250827 f1: 0.8755394760658388\n",
      "Question 5 accuracy: 0.5088077756989146 f1: 0.5723452997113391\n",
      "Question 6 accuracy: 0.7651174257519369 f1: 0.8657647032268541\n",
      "Question 7 accuracy: 0.6976463065655303 f1: 0.8171270315241876\n",
      "Question 8 accuracy: 0.5756408264719589 f1: 0.697825399240227\n",
      "Question 9 accuracy: 0.7052828642382243 f1: 0.8228891381217327\n",
      "Question 10 accuracy: 0.4860987092285766 f1: 0.491729945304916\n",
      "Question 11 accuracy: 0.5951647292712196 f1: 0.7200174884469124\n",
      "Question 12 accuracy: 0.8574164758540412 f1: 0.9231116057437465\n",
      "Question 13 accuracy: 0.6982791965831595 f1: 0.14717664908184286\n",
      "Question 14 accuracy: 0.6596652504880075 f1: 0.7870382708249072\n",
      "Question 15 accuracy: 0.5113490171179751 f1: 0.4834194080501323\n",
      "Question 16 accuracy: 0.6936127865848029 f1: 0.8140554695738217\n",
      "Question 17 accuracy: 0.6384500386128203 f1: 0.769291948152588\n",
      "Question 18 accuracy: 0.9454701420456464 f1: 0.9719706678687654\n",
      "Overall accuracy: 0.7066505986300518\n",
      "Overall F1 score: 0.7513663395303554\n"
     ]
    }
   ],
   "source": [
    "########## XGBoost ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'XGBoost', \n",
    "    XGBClassifier(eval_metric='error', use_label_encoder=False), \n",
    "    params, \n",
    "    False)\n",
    "\n",
    "if res:\n",
    "    best_params_dict['XGBoost'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## RandomForest ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(1, 50),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'RandomForest', \n",
    "    RandomForestClassifier(), \n",
    "    params, \n",
    "    False)\n",
    "\n",
    "if res:\n",
    "    best_params_dict['RandomForest'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CatBoost ##########\n",
    "\n",
    "## Load alternate train data for catboost\n",
    "cat_train = pd.read_csv('CatBoostData.csv')\n",
    "\n",
    "# Specify the categorical columns to be used by the CatBoost model\n",
    "cat_features = ['event_name_mode', 'fqid_mode', 'room_fqid_mode', 'text_mode']\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'iterations': [100, 300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'depth': [3, 4, 6, 8],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    cat_train, \n",
    "    labels, \n",
    "    'CatBoost', \n",
    "    CatBoostClassifier(cat_features=cat_features), \n",
    "    params, \n",
    "    False)\n",
    "\n",
    "## Add best hyperparameters to dictionary\n",
    "if res:\n",
    "    best_params_dict['CatBoost'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LightGBM ##########\n",
    "\n",
    "## Define hyperparameter dict\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "## Set last argument to true if want to carry out randomized search for best hyperparams\n",
    "res = train_model(\n",
    "    train, \n",
    "    labels, \n",
    "    'LightGBM', \n",
    "    LGBMClassifier(), \n",
    "    params, \n",
    "    False)\n",
    "\n",
    "if res:\n",
    "    best_params_dict['LightGBM'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m q_no \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     12\u001b[0m     select \u001b[38;5;241m=\u001b[39m train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0-4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m     cat_select \u001b[38;5;241m=\u001b[39m \u001b[43mcat_train\u001b[49m[cat_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0-4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m q_no \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m13\u001b[39m:\n\u001b[1;32m     15\u001b[0m     select \u001b[38;5;241m=\u001b[39m train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5-12\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_train' is not defined"
     ]
    }
   ],
   "source": [
    "## Train ensemble with final estimators\n",
    "final_estimators = [LogisticRegression(), DecisionTreeClassifier(max_depth=7)]\n",
    "\n",
    "for final_estimator in final_estimators:\n",
    "\n",
    "    ## Print the final estimator being used for the ensemble\n",
    "    print(\"Final estimator:\", str(final_estimator))\n",
    "\n",
    "    ## Initialize vars to store model scores\n",
    "    overall_acc, overall_f1 = 0, 0\n",
    "\n",
    "    ## Train model for each of the 18 questions\n",
    "    for q_no in range(1, 19):\n",
    "        if q_no <= 3:\n",
    "            select = train[train['level_group'] == '0-4']\n",
    "            cat_select = cat_train[cat_train['level_group'] == '0-4']\n",
    "        elif q_no <= 13:\n",
    "            select = train[train['level_group'] == '5-12']\n",
    "            cat_select = cat_train[cat_train['level_group'] == '5-12']\n",
    "        else:\n",
    "            select = train[train['level_group'] == '13-22']\n",
    "            cat_select = cat_train[cat_train['level_group'] == '13-22']\n",
    "\n",
    "        ## Create train and validation splits\n",
    "        train_X, validate_X = train_test_split(select, test_size=0.2)\n",
    "        cat_train_X, cat_validate_X = train_test_split(cat_select, test_size=0.2)\n",
    "\n",
    "        train_y = labels.loc[(labels['session'].isin(train_X['session_id'])) & (labels['q'] == q_no)]\n",
    "        validate_y = labels.loc[(labels['session'].isin(validate_X['session_id'])) & (labels['q'] == q_no)]\n",
    "\n",
    "        train_X = train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        cat_train_X = cat_train_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        train_y = train_y['correct']\n",
    "\n",
    "        validate_X = validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        cat_validate_X = cat_validate_X.drop(['session_id', 'level_group'], axis=1)\n",
    "        validate_y = validate_y['correct']\n",
    "\n",
    "        # Train the four models with the optimized hyperparameters\n",
    "        xgb_model = XGBClassifier(best_params_dict['XGBoost'][q_no - 1]).fit(train_X, train_y)\n",
    "        rf_model = RandomForestClassifier(best_params_dict['RandomForest'][q_no - 1]).fit(train_X, train_y)\n",
    "        cat_model = CatBoostClassifier(best_params_dict['CatBoost'][q_no - 1], cat_features=cat_features).fit(cat_train_X, train_y)\n",
    "        lgbm_model = LGBMClassifier(best_params_dict['LightGBM'][q_no - 1]).fit(train_X, train_y)\n",
    "\n",
    "        ## Obtain the predicted probabilities for each class for each model\n",
    "        rf_pred = rf_model.predict_proba(validate_X)[:, 1]\n",
    "        xgb_pred = xgb_model.predict_proba(validate_X)[:, 1]\n",
    "        cat_pred = cat_model.predict_proba(cat_validate_X)[:, 1]\n",
    "        lgbm_pred = lgbm_model.predict_proba(validate_X)[:, 1]\n",
    "\n",
    "        ## Stack the predictions\n",
    "        stacked_predictions = np.column_stack((xgb_pred, rf_pred, cat_pred, lgbm_pred))\n",
    "\n",
    "        ## Train the final_estimator\n",
    "        final_estimator.fit(stacked_predictions, validate_y)\n",
    "\n",
    "        ## Use the meta-learner to make the final prediction\n",
    "        ensemble_pred = final_estimator.predict(stacked_predictions)\n",
    "\n",
    "        ## Calculate the accuracy and F1 score using cross_val_score\n",
    "        question_acc = np.mean(ensemble_pred == validate_y)\n",
    "        question_f1 = f1_score(validate_y, ensemble_pred)\n",
    "        overall_acc += question_acc\n",
    "        overall_f1 += question_f1\n",
    "        print(\"Question\", q_no, \"accuracy:\", question_acc, \"f1:\", question_f1)\n",
    "\n",
    "    print(\"Overall accuracy:\", overall_acc)\n",
    "    print(\"Overall F1 score:\", overall_f1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_preprocessed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame()\n",
    "\n",
    "def append_qnum(col, qnum):\n",
    "    return str(col) + '_q' + str(qnum)\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    if q_no <= 3:\n",
    "        select = test[test['level_group'] == '0-4']\n",
    "    elif q_no <= 13:\n",
    "        select = test[test['level_group'] == '5-12']\n",
    "    else:\n",
    "        select = test[test['level_group'] == '13-22']\n",
    "\n",
    "    session_id = select['session_id'].apply(append_qnum, qnum=q_no).tolist()\n",
    "    select = select.drop(['session_id','level_group'], axis=1)\n",
    "\n",
    "    model = pickle.loads(stored_models['XGBoost'][q_no-1])\n",
    "    pred = model.predict(select)\n",
    "    \n",
    "    df = pd.DataFrame({'session_id': session_id, 'correct': pred})\n",
    "    preds = pd.concat([preds, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds\n",
    "preds.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
